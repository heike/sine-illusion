% !TeX program = pdfLaTeX
\documentclass[12pt]{article}
\usepackage{natbib}
\usepackage{fullpage}
\usepackage{color}
\usepackage[dvipsnames,svgnames]{xcolor}
\usepackage[colorlinks=TRUE, linkcolor=blue]{hyperref}
\usepackage{wrapfig,float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{url}
\usepackage{ulem}
\usepackage[section]{placeins}
\usepackage{sidecap}

% test change
% help with editing and coauthoring
\usepackage[colorinlistoftodos]{todonotes}

\graphicspath{{figure/}}
\renewcommand{\floatpagefraction}{.99}

\newcommand{\range}[1]{{\text{range}\left(#1\right)}}
\newcommand{\s}[2]{{_{#1}s^{ #2}}}
\newcommand{\atan}[1]{\text{atan}\left({#1}\right)}
\newcommand{\done}[2][inline]{\todo[color=SpringGreen, #1]{#2}}  % for todos that have been seen and dealt with
\newcommand{\meh}[2][inline]{\todo[color=White, #1]{#2}}   % for todos that may no longer be relevant 
\newcommand{\comment}[2][inline]{\todo[color=SkyBlue, #1]{#2}} % for comments that may not be "to-do"s
\newcommand{\mcomment}[1]{\todo[color=SkyBlue]{#1}} % for margin comments

\newcommand{\newtext}[1]{\todo[inline, color=White]{ \color{OliveGreen}{#1}}} % new text - not necessarily something to be done
\newcommand{\newdo}[1]{\todo[inline, color=Plum]{#1}} % new to do item
\newcommand{\move}[1]{\todo[inline, color=Lime]{#1}} % new to do item


<<setup, fig.keep='all', cache=FALSE, echo=FALSE, eval=TRUE>>=
rm(list=ls())
options(replace.assign=TRUE,width=70)
require(knitr)
opts_chunk$set(fig.path='figure/fig-', cache.path='cache/', fig.align='center', fig.width=5, fig.height=5, fig.show='hold', par=TRUE, cache=TRUE, concordance=TRUE, autodep=TRUE)
library(reshape2)
suppressMessages(library(ggplot2))
library(plyr)
suppressMessages(library(gridExtra))

source("code/functions.r")

@




\title{Signs of the Sine Illusion -- why we need to care}
\author{Susan Vanderplas, Heike Hofmann}%, Dianne Cook}%, Xiaoyue Cheng}

\begin{document}
\maketitle
\begin{abstract}
The sine illusion, which is part of a set of optical illusions which occur based on a conflict between a stimuli and the real-world situation which can cause similar stimuli, has a notable impact on perception of time-series data with a seasonal component. In this paper, we discuss the reasons for the illusion and various strategies which might be useful to break the illusion or reduce its strength, demonstrating the presence of the illusion in real-world and theoretical situations. We also present data from user studies which demonstrate the dramatic effect the sine illusion can have on conclusions drawn from displayed data.
\end{abstract}
\tableofcontents

\section{Introduction}
Graphics are powerful tools for summarizing large or complex data. The main premise of statistical graphics is that any graphical representation of the data has to be ``true'' to the data \citep[see e.g.][]{tufte, wainer:2000, robbins:2005} i.e.~a measurable quantity of a graphical element in the representation has to  directly reflect some aspect of the underlying data. Generally, we see a lot of discussion on keeping true to the data in the framework of (ab)using three dimensional effects in graphics. \citep{tufte} goes as far as defining a {\it lie-factor} of a chart as the ratio of the size of an effect in the data compared to the size of an effect shown, with the premise that any large deviations from one indicate a misuse of graphical techniques. Computational tools help us ensure technical trueness -- but this brings up the additional question of how we deal with situations that involve innate inability or trigger learned misperceptions in the audience. In this paper we want to raise awareness for one of these situations, show that it occurs frequently in our dealings with graphics and provide a set of strategies at solving or avoiding it.


<<example,echo=FALSE, include=FALSE>>=
#source("./data/NewOzoneData.R")
datasub <- read.csv("data/Ozone-subset.csv")
nsite <- length(unique(datasub$SiteID))
qplot(data=datasub, x=jitter(Tmax), y=Ozone, geom="point", colour=I("grey30"), alpha=I(.5), xlab="Temperature (F)", ylab="8-hour Average Ozone Concentration (ppm)") + geom_line(aes(x=Tmax, y=fit), size=1.25, colour="steelblue") + theme_bw()
qplot(data=datasub, x=jitter(Tmax), y=resid, geom="point", colour=I("grey20"), alpha=I(.5), xlab="Temperature (F)", ylab="Residual Ozone Concentration (ppm)") + geom_line(aes(x=Tmax, y=0*resid), size=1.25, colour="steelblue") + theme_bw()
@

\begin{figure}[h!tbp]\centering
\begin{subfigure}[b]{.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{figure/fig-example1}
  \caption{\small Scatterplot of Ozone and Temperature in Houston, 2011. A loess fit is overlaid to show the overall trend.}
  \label{fig:example1}
\end{subfigure}\hfill
\begin{subfigure}[b]{.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{figure/fig-example2}
  \caption{\small Scatterplots of Ozone and Temperature de-trended according to the loess fit in (a). \\ \phantom{text to get to the next line}}
  \label{fig:example2}
\end{subfigure}
\caption{\label{fig:exampleFull1} Scatterplots of Ozone and Temperature in Houston, 2011. The increase in variability over the temperature range is more pronounced in the de-trended plot on the right.}
\end{figure}

As a first example let us consider the relationship between ozone concentration and temperature. Ozone concentrations were measured from \Sexpr{nsite} locations in the Houston area \citep{epa}, and temperature data is provided by the NCDC \citep{noaa} site at Hobby International Airport, located near the center of Houston. 

Figure~\ref{fig:example1} shows daily measurements of 8-hour average ozone concentration and temperature at several sites in Houston, for days in 2011 with temperatures above $45^\circ$F  and dew points of less than $60^\circ$F. %(as ozone concentration is related to temperature and humidity)
A loess smooth line is added for reference. Does the variability of ozone concentrations stay the same across the range of temperatures? We might agree that there is an increase in variability of ozone concentrations for temperatures above $80^\circ$F, but based on figure~\ref{fig:example1} not doubt    homogeneity  elsewhere. 

% Is the variance trend in (a) consistent with the residual plot in (b)?
% 
% Figure~\ref{fig:example2} shows a residual plot of the same data, created by subtracting the loess fit line from the observed data, leaving only the variability behind. 
%\done{I like this example! But we still need to suggest that the trumpet shape in the residuals comes as a surprise to lots of people.}


This evaluation changes, when considering Figure~\ref{fig:example2}: the scatterplot shows a loess based de-trended residual of temperature. A previously almost invisible increase in variability of ozone measurements with increasing temperatures now becomes apparent.
%The steady increase in variance over the temperature range is much more pronounced than in the  plot on the left.
This phenomenon, caused by the change in the slope of the trend line,  is  known as the  {\it sine illusion} in the literature on cognition and human perception  or {\it line width illusion} in the statistical graphics literature. 


%The change in slope of the trend is causing this phenomenon, which is  known as
% in the Figure \ref{fig:example1} due to the changes in slope, but is very obvious in the residual plot in Figure \ref{fig:example2}. The sine illusion is responsible for the appearance of constant variance in Figure \ref{fig:example1}, but once the trend has been removed, and thus the corresponding changes in slope are no longer a factor, the increase variance becomes more visible.

The illusion is a frequent occurrence in statistical graphics, and  displays should therefore be thoughtfully considered to minimize its effect visually and acknowledge its influence. 
In the cognitive literature, \cite{day:1991} first documented the illusion in the context of vertical lines along a sinusoidal curve. Figure~\ref{fig:original} shows a sketch of this: line segments are centered evenly spaced along the curve. Line segments are of equal length but appear longer in the peaks and troughs due to the illusion. 
The parameters that influence the strength of the illusion are the amplitude of the curve and the length of the line segments.
As the length of the line segments increases,  the apparent difference in the length of the line segments decreases. Any modification that increases the change in slope under which the curve appears, such as an increase in the amplitude of the curve or a more extreme aspect ratio, reinforces the apparent difference in line lengths. 


<<functions, echo=FALSE, eval=TRUE>>=
f <- function(x) 2*sin(x)
fprime <- function(x) 2*cos(x)
f2prime <- function(x) -2*sin(x)
@
<<original, dependson='functions', echo=FALSE, fig.width=5, fig.height=5, include=FALSE>>=
qplot(x=x, xend=xend, y = ystart, yend=yend, geom="segment", data=createSine(40, 1, f=f, fprime=fprime, f2prime)) +
  theme(panel.grid.major=element_blank(), panel.background = element_rect(fill = "white", 
                colour = "black"), plot.margin = unit(c(-1,0,-3,0), "cm"), 
       panel.grid.minor=element_blank(), panel.background=element_blank(),
       axis.title = element_blank(), axis.ticks = element_blank(), 
       axis.text = element_blank()) + coord_equal(ratio=1)
@
<<original-redo, echo=FALSE, fig.keep='none', results='hide', fig.keep='all'>>=
cairo_pdf("./figure/fig-original-redo.pdf", width=5, height=5)
df1 <- createSine(20,1, f=f, fprime=fprime, f2prime=f2prime)
df1$colour <- c(rep("A", 5), "A", rep("A", 13), "A")
qplot(x=xstart, xend=xend, y = ystart, yend=yend, geom="segment", data=df1, colour=I("grey20")) +
  theme(panel.grid.major=element_blank(), 
        panel.background = element_rect(fill = "white", colour = "black"),
        panel.grid.minor=element_blank(), panel.background=element_blank(),
        axis.title = element_blank(), axis.ticks = element_blank(), 
        axis.text = element_blank()) + coord_equal(ratio=1) + 
  geom_segment(x=-pi/12, xend=2*pi+pi/12, y=0, yend=0, colour="grey80", linetype=2)+
  geom_segment(aes(x=x, xend=xend, y=y, yend=yend), colour="grey50", 
               data=data.frame(x=c(df1$x[6],  mean(df1$x[5:6]), mean(df1$x[5:6])), 
                               xend = c(mean(df1$x[5:6]), mean(df1$x[5:6]), df1$x[6]),
                               y = c(df1$y[6], df1$y[6], 0), 
                               yend = c(df1$y[6], 0, 0)), size=1) + 
  geom_text(aes(x=df1$x[5], y=df1$y[6]/2, label="s"), hjust=1, vjust=.5, size=10, colour="grey50") + 
  geom_segment(aes(x=x, xend=xend, y=y, yend=yend), colour="grey60", 
             data=data.frame(x=c(df1$x[20],  mean(df1$x[19:20]), mean(df1$x[19:20])), 
                             xend = c(mean(df1$x[19:20]), mean(df1$x[19:20]), df1$x[20]),
                             y = c(df1$ystart[20], df1$ystart[20], df1$yend[20]), 
                             yend = c(df1$ystart[20], df1$yend[20], df1$yend[20])), size=1) +
  geom_text(aes(x=df1$x[19], y=df1$y[20], label="\u2113"), hjust=1, vjust=.5, size=10, colour="grey60")
dev.off()
@
\begin{figure}[hbtp]
\centering
\includegraphics[keepaspectratio=true, width=.5\linewidth]{figure/fig-original}
% \includegraphics[keepaspectratio=true, width=\linewidth]{fig-original-redo.pdf}
\caption{The original sine illusion was demonstrated on evenly spaced vertical lines centered around a sinusoidal curve of $f(x) = \sin(x)$. The lines in the peak and trough of the curve appear to be longer than in the other regions.\label{fig:original}}
%The right graph illustrates the parameters determining the appearance of the illusion: $s$ denotes the amplitude of the function, $\ell$ the length of the line segments.
\end{figure}
%The first documentation we could find of this illusion,
More recently the illusion has been shown in non-sinusoidal curves \citep{cleveland:1984, schonlau:2003, robbins:2005, marie:2013}, but the underlying effect seems to be the same, in the sense the illusion is not triggered by the periodic nature of the underlying trendline but only by  changes to its slope. Figure \ref{fig:twoillusions-simulation} shows three panels, which all exhibit the illusion. From left to right, the trend comes from (a) a periodic function, (b) a periodic component added to an exponential function, and (c) an exponential function on its own.
While all three graphs seem to show nonconstant variance along the main trend; in reality, the variance is constant in all of them. Clearly, the illusion does not rely on the periodicity of the function for which it was named, but is a symptom of the change in curvature that comes with the periodicity.
%, instead the ``line width illusion" and the ``sine illusion" are symptoms of the same phenomenon, even though the cognitive literature and the graphics literature refer to the illusion differently. 


<<simulation1Sine, echo=FALSE, fig.width=4, fig.height=4, include=FALSE>>=
alph <- .25
x <- rep(seq(0,2*pi*2, length=120), each=50)
y <- rnorm(n=length(x), mean=sin(x), sd=0.2)
qplot(x,y, geom="jitter", alpha=I(alph))+ 
  geom_line(y=0*x) + 
  scale_x_continuous(breaks=seq(0, 4*pi, by=pi), 
                     labels=c("0", expression(paste(pi)), 
                              expression(paste("2", pi)), 
                              expression(paste("3", pi)), 
                              expression(paste("4", pi)))) +
  theme_bw()
#x <- rep(seq(0,2*pi*2, length=120), each=100)
y <- rnorm(n=length(x), mean=1/10*(-x+pi)^2+sin(x), sd=0.2)
qplot(x,y, geom="jitter", alpha=I(alph))+ 
  geom_line(y=1/10*(-x+pi)^2) + 
  scale_x_continuous(breaks=seq(0, 4*pi, by=pi), 
                     labels=c("0", expression(paste(pi)), 
                              expression(paste("2", pi)), 
                              expression(paste("3", pi)), 
                              expression(paste("4", pi)))) +
  theme_bw()
#x <- rep(seq(0,2*pi*2, length=120), each=100)
y <- rnorm(n=length(x), mean=1/10*(-x+pi)^2, sd=0.2)
qplot(x,y, geom="jitter", alpha=I(alph))+ 
  geom_line(y=1/10*(-x+pi)^2) + 
  scale_x_continuous(breaks=seq(0, 4*pi, by=pi), 
                     labels=c("0", expression(paste(pi)), 
                              expression(paste("2", pi)), 
                              expression(paste("3", pi)), 
                              expression(paste("4", pi)))) +
  theme_bw()
@
\begin{figure}[h!tbp]\centering
\begin{subfigure}[b]{.31\linewidth}
  \centering
  \includegraphics[keepaspectratio=TRUE,width=\linewidth]{figure/fig-simulation1Sine1}
  \caption{\small Seasonality, No Trend}
  \label{simulation1}
\end{subfigure}
\begin{subfigure}[b]{.31\linewidth}\centering
  \includegraphics[keepaspectratio=TRUE,width=\linewidth]{figure/fig-simulation1Sine2}
  \caption{\small Seasonality and Trend}
  \label{simulation2}
\end{subfigure}
\begin{subfigure}[b]{.31\linewidth}\centering
  \includegraphics[keepaspectratio=TRUE,width=\linewidth]{figure/fig-simulation1Sine3}
  \caption{\small Trend, No Seasonality}
  \label{simulation3}
\end{subfigure}
\caption{Set of three scatterplots of simulated data with constant variance. Plot (a) shows seasonality without any underlying trend, (b) shows seasonality superimposed on a quadratic trend, and (c) shows a quadratic trend without seasonality. Though all three sets of simulated data have constant variance, none of the variances appear constant due to the sine illusion.}\label{fig:twoillusions-simulation}
\end{figure}

Sections \ref{perceptualexplanations} and \ref{statisticalgraphics} explore the perceptual and statistical literature examining this illusion.
%\FloatBarrier
\subsection{Statistical Graphics and the Sine Illusion}\label{statisticalgraphics}
The sine illusion demonstrated in Figures \ref{fig:exampleFull1} and \ref{fig:original} has been frequently noted in statistical graphics, though usually not as an optical illusion. Rather, the problem is typically identified as the difficulty of visually subtracting two curves, and the resulting erroneous conclusions when this process goes awry. Figure \ref{fig:playfair-debt} presents the possibly oldest example of this common phenomenon \citep{playfair, playfair2}: Playfair's chart of the balance of trade between England and the East Indies shows time series of the trade value for imports  and exports between the countries in the 18th century. The shaded area on the chart is named ``balance against England", suggesting that the difference between the lines is of main importance. This difference in trading values is encoded as the difference between the lines along the vertical axis. However, the 
 vertical distance  between  two lines provides a  much less visually salient cue than the orthogonal width between the lines. This results in  an underestimation \citep{cleveland:1984} of the difference in trades around 1763, which is of a much higher (about 1.5 fold) magnitude as around 1770, but appears  smaller than that.  
% that is, the width of the line segment which is perpendicular to the tangent line at a given point.

\begin{figure}[h!tbp]
\centering
\includegraphics[keepaspectratio=TRUE,width=.8\linewidth]{images/PlayfairExportImports}
\caption{Playfair's graph of exports to and imports from the East Indies demonstrates that the line width illusion is not only found on sinusoidal curves but is present whenever the slope of the lines change dramatically. The increase in both imports and exports circa 1763 does not appear to portray as large of a deficit as that in 1710, even though they are of similar magnitude.}
\label{fig:playfair-debt}
\end{figure}

%Another example of the illusion is shown in Figure \ref{fig:robbins-graph} \citep{robbins:2005}, which contains two  exponential curves shifted vertically by a constant.%, i.e.~$f_1(x) = e^x$ and $f_2(x) = e^x + 1$.  
%In spite of this constant vertical distance, the lines appear to be closing in on each other. %$x=2.5$ than at $x=0$, even though mathematically it is obvious that the distance between them is constant. 
%
The line width illusion is triggered by the change in slope -- as the slope increases, the apparent distance between the two lines decreases. %, even though the lines represent a constant vertical shift.
%<<effectivegraphsfig,echo=FALSE, include=FALSE>>=
%x <- seq(0, 2.5, .01)
%y1 <- exp(x)
%y2 <- exp(x)+1
%df <- data.frame(x=x, y=y1, y2=y2)
%qplot(data=df, x=x, y=y, geom="line") + geom_line(aes(y=y2)) + theme_bw()
%@
%\begin{SCfigure}
%\centering
%\includegraphics[width=.45\linewidth]{figure/fig-effectivegraphsfig}
%\caption{Graphs of two vertically shifted exponential curves, $y=e^x$ and $y=e^x+1$. Due to the line width illusion the graphs appear to converge as $x$ increases.  \citep[This chart is a replication of Figure 2.16 in][]{robbins:2005}\label{fig:robbins-graph}}
%\end{SCfigure}

%\FloatBarrier
\subsection{Perceptual Explanations for the Sine Illusion}\label{perceptualexplanations}
While not thoroughly examined in the sensation and perception literature, the sine illusion has been classified as part of a group of geometrical optical misperceptions  related to the M\"uller-Lyer illusion \citep{day:1991} or the Poggendorf illusion \citep{poggendorf}, which puts the illusion into the framework of context-based illusions.
\cite{day:1991} suggest that
the sine illusion occurs due to misapplication of perceptual experience with the three-dimensional world to a two-dimensional ``artificial" display of data. 

Experience with real-world objects suggests that the stimulus of figure~\ref{fig:original} is very similar to a slightly angled top view of the 3-dimensional figure of a strip or ribbon describing waves in a third dimension, such as e.g.~a road does on rolling hills. This is sketched out in figure~\ref{ribbon1}. Our experience suggests immediately that  changes in the width of the road are unlikely and resolves the illusion. While figure~\ref{ribbon1} shows the line segments slightly angled towards each other,  the figure \ref{ribbon2} shows a variation of the same plot with a  vanishing point set further away from the viewer. This makes the line segments almost parallel to each other and therefore more closely resembles the sketch of figure~\ref{fig:original}, in which the sine illusion was originally presented.

%By treating the graph as a two-dimensional projection of a three-dimensional figure, the illusion disappears and the line widths seem once more to be constant.


% Figure \ref{fig:ribbon-illusion} shows a possible three-dimensional context for the classical sine illusion; two ribbons are shown at varying perspective strengths. \todo[inline]{OK, we need to slow down here, but I'm not sure how to say it. That's why I'm asking all these questions.}
% \todo[inline]{How do the perspective plots relate to the illusion - in words. I can see it, but we need to describe it in the text as well. }
% \todo[inline]{Does the 3d perspective resolve the illusion?}
% 
% \todo[inline]{What is the difference between the first and the second perspective plot?}
% The first appears more natural \todo[inline]{What do you mean by more 'natural'?}, but the second still appears three-dimensional \todo[inline]{Why?} and is much closer to the sine illusion stimuli \todo[inline]{Why is it closer?}  with added shading. 

\begin{figure}[h!tbp]\centering
<<ribbon-illusion,echo=FALSE, include=FALSE, fig.width=5, fig.height=5>>=

f <- function(x) 2*sin(x)
fprime <- function(x) 2*cos(x)
f2prime <- function(x) -2*sin(x)

x <- seq(0, 2*pi, length=42)[2:41]
data <- do.call("rbind", lapply(seq(-.5, .5, 1), function(i) data.frame(x=x, y=2*sin(x), z=i)))

data.persp <- acast(data, x~z, value.var="y")
x <- sort(unique(data$x))
y <- sort(unique(data$y))
z <- sort(unique(data$z))

persp(x, z, data.persp,  xlab="", ylab="", zlab="", theta=0, phi=45, border="black", shade=.35, col="white", xlim=c(-pi/12, 2*pi+pi/12), ylim=c(-1.75, 1.75), scale=FALSE, box=FALSE, expand=3/pi, d=3) # , ltheta=0, lphi=-15
persp(x, z, data.persp,  xlab="", ylab="", zlab="", theta=0, phi=45, border="black", shade=.35, col="white", xlim=c(-pi/12, 2*pi+pi/12), ylim=c(-1.75, 1.75), scale=FALSE, box=FALSE, expand=3/pi, d=50) # , ltheta=0, lphi=-15

@
\begin{subfigure}[t]{.49\linewidth}\centering
\includegraphics[width=\linewidth, keepaspectratio=TRUE, trim=0in 1.5in 0in 1.5in]{figure/fig-ribbon-illusion1}
\caption{Perspective plot of sine illusion\label{ribbon1}}
\end{subfigure}
\begin{subfigure}[t]{.49\linewidth}\centering
\includegraphics[width=\linewidth, keepaspectratio=TRUE, trim=0in 1.5in 0in 1.5in]{figure/fig-ribbon-illusion2}
\caption{Perspective plot, vanishing point near infinity.\label{ribbon2}}
\end{subfigure}
\caption{Two different perspective projections of the same data responsible for the sine illusion. The first projection angles the lines and appears much more natural, but the second projection suggests that the lines do not need to be angled to create the same three-dimensional impression.\label{ribbon}}
\end{figure}



<<originalgrid, dependson='data', echo=FALSE, include=FALSE, fig.width=5, fig.height=4>>=
f <- function(x) 2*sin(x)
fprime <- function(x) 2*cos(x)
f2prime <- function(x) -2*sin(x)

dframe <- createSine(n = 40, len = 1, f=f, fprime=fprime, f2prime)
require(grid)
qplot(x=x, xend=xend, y = ystart*ell, yend=yend*ell, geom="segment", data=dframe) +
  theme(panel.grid.major.y=element_line(colour="grey75"), 
        panel.grid.minor.y=element_line(colour="grey85"), 
        panel.grid.major.x=element_blank(),
        panel.background = element_rect(fill = "white", 
                colour = "black"),
       panel.grid.minor.x=element_blank(), panel.background=element_blank(),
       axis.title = element_blank(), axis.ticks = element_blank(), 
       axis.text = element_blank(), 
        plot.margin = unit(c(.1,.1,.1,.1), "cm")) + coord_equal(ratio=1) + 
  geom_segment(size=1.5, data=dframe[c(31, 38),]) 
@
\begin{SCfigure}
\centering
\caption{\label{fig:original-grid} The sine illusion with two individual lines highlighted. Horizontal grid lines do not help  to resolve the illusion, even though they provide a clear basis for comparison of line lengths. Readers are much better at assessing the length of the two singled out line segments; they are equal.}
\includegraphics[width=.5\linewidth]{figure/fig-originalgrid}
\end{SCfigure}

While it is typically a bad idea to use three-dimensional representations when two dimensions are adequate to display the data \citep{tufte}, it might present a viable avenue to counteract a visual illusion. However, creating a three-dimensional projection of two-dimensional data is not simple. The projection that best resolves the illusion  likely is highly subjective and influenced by choices of angle and color gradient for depth cues. 
%and would also lead to distortions and instability in the visual display. In particular, there does not seem to be an simple guideline for determining the projection angle or color gradient  to create the illusory depth to remove the optical illusion. 

%That is, the illusion breaks down if the visual heuristic is pre-empted by an attempt to view the graph as if it were three dimensional or if each piece is considered without the surrounding context. 

The contextual cues of the overall trend are critical to the sine illusion's effect;  the illusion  only  holds when a substantial portion of the graph is considered simultaneously, which triggers our innate ability of perceiving one whole rather than the individual parts it consists of \citep[principle of grouping][]{wolfe2012sensation}.
%without regard to the perceptual mechanisms at play. 
Considering only one or two line segments at a time resolves the illusion. The bold lines in figure~\ref{fig:original-grid} are clearly of the same length.  Comparisons of individual line lengths is visually a fairly simple task, and is done with a relatively high accuracy \citep{cleveland:1984}. 
\citet{day:1991} contains a more thorough discussion of how much surrounding context is required for the illusion to persist. 
%The illusion arises when sufficient context is available to induce an ambiguously three-dimensional figure.

%\FloatBarrier
\subsection{Geometry of the Illusion}
%We have previously alluded to the fact that the sine illusion depends on the change in the slope of the underlying function; what follows is a geometric explanation of why this occurs. 
%Our perceptual system is particularly well optimized for three dimensions; in figure~\ref{fig:original}  this leads us to perceive the  shortest line between the top and bottom curves as the distance between the curves, i.e. the {\it orthogonal} width,  rather than the vertical distance. 
In Figure~\ref{fig:original} we have seen that the our preference in evaluating line width is to assess {\it orthogonal} width rather than the difference along the vertical axis. 
Figure~\ref{fig:OrthogonalWidth} demonstrates the change in orthogonal width as the slope of the line tangent to the graph of $f$ changes; these changes correspond to our perception of apparent line length. 
<<transform-illustration,echo=FALSE, message=FALSE, warning=FALSE, include=FALSE, fig.width=7.5, fig.height=5>>=
f <- function(x) 2*sin(x)
fprime <- function(x) 2*cos(x)
f2prime <- function(x) -2*sin(x)
library(plyr)
dframe <- createSine(n = 150, len = 1, f=f, fprime=fprime, f2prime=f2prime)
dframe$ystartcts <- dframe$ystart
dframe$yendcts <- dframe$yend
dframe[1:150,c(2, 3, 5, 6)] <- NA
dframe[(1:15)*10-5, c(2, 3)] <- dframe[(1:15)*10-5, 1] 
dframe[(1:15)*10-5, 5] <- dframe[(1:15)*10-5, 4] - .5
dframe[(1:15)*10-5, 6] <- dframe[(1:15)*10-5, 4] + .5
dframe$type <- "Vertical Width"

idx <- which(!is.na(dframe$xstart))
dframe$ell <- dframe$ell/2
dframe.1 <- getSecantSegment(dframe$xstart[idx], dframe, f, fprime, f2prime)
dframe.1$x <- dframe$x[idx]
dframe.1$y <- dframe$y[idx]
dframe.1$ystartcts <- dframe$ystartcts[idx]
dframe.1$yendcts <- dframe$yendcts[idx]
names(dframe.1) <- c("x", "y", "deriv", "xstart", "xend", "ystart", "yend", "ell", "ell.quad1", "ell.quad2", "type", "a", "ystartcts", "yendcts")
dframe.1$vangle <- with(dframe.1, atan(deriv))
dframe <- rbind.fill(dframe, dframe.1)
dframe$type <- factor(dframe$type)

qplot(x=x, y=y, geom="line", data=dframe, colour=I("grey50")) + theme_bw() + 
  geom_line(aes(y=ystartcts), colour="grey50", linetype=4) + 
  geom_line(aes(y=yendcts), colour="grey50", linetype=4) +
  geom_segment(data=subset(dframe, !is.na(type)), 
               aes(x=xstart, xend = xend, y=ystart, yend=yend, colour=type, linetype=type), size=0.8)  + 
  xlab("") + ylab("")  +
  coord_equal(ratio=1) + scale_colour_manual("", values=c("blue", "grey30")) + 
  geom_text(aes(label=paste("theta", "%~~%", round(abs(vangle)/pi*180), "^o", sep=""), 
                x=pmax(xstart, xend)/2+x/2+.35 , y=y-sign(vangle)*.6+.02), colour="blue",
            data=dframe.1, parse=TRUE, hjust=.9, vjust=.5, size=3) + 
  scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), 
                     labels=c("0", expression(paste(pi,"/2")), expression(pi), 
                              expression(paste("3",pi, "/2")), expression(paste("2",pi)))) +
  scale_linetype_manual("", values=c(1,2)) + 
  theme(legend.key.width = unit(3, "line"))
@
\begin{figure}[h!tbp]
\centering
\includegraphics[width=.75\linewidth, keepaspectratio=TRUE]{fig-transform-illustration}
\caption{\label{fig:OrthogonalWidth} The sine illusion with  lines  orthogonal to the tangent line at $f(x)$. The perception that the vertical length changes with $f(x)$ corresponds to changes in actual orthogonal width due to the change in secant angle. 
}
\end{figure}
%Secants and vertical lines are both shown  in figure~\ref{fig:OrthogonalWidth}. 
The illusion is most pronounced in regions where the angle between the orthogonal  and the vertical line is large. 
The perceived length of the vertical line changes with the angle of the line perpendicular to the slope of $\sin(x)$, suggesting that the sine illusion stems from a conflict between the visual system's perception of figure width and the mathematical judgement necessary to determine the length of the vertical lines. 
<<geometry,echo=FALSE, fig.height=2.1, fig.width=3.5, include=FALSE>>=
f <- function(x, a=1, b=0) a*x + b
x  <- seq(-.2,.2, .1)
ell <- .1
a <- 1
intx <- ell/(a + 1/a)
ribbon <- data.frame(x = x, ytop = f(x) + ell, ybottom = f(x)-ell)
aline <- data.frame(xtop = 0,    xbottom = 0,   ytop = f(0) + ell,  ybottom = f(0) - ell, label="vertical width")
bline <- data.frame(xtop = -intx, xbottom = intx, ytop = f(-intx)+ell, ybottom = f(intx)-ell, label="extant width")
widths <- rbind(aline, bline)
qplot(data=ribbon, x=x, ymin=ybottom, ymax=ytop, geom="ribbon", fill=I("grey")) +
  theme(panel.grid.major=element_blank(), 
#        panel.background = element_rect(fill = "white", colour = "black"),
        panel.grid.minor=element_blank(), panel.background=element_blank(),
        axis.title = element_blank(), axis.ticks = element_blank(), 
        axis.text = element_blank()) +  
  geom_segment(data=widths, aes(x=xbottom, xend = xtop, y=ybottom, yend=ytop, linetype=label)) +
  geom_text(data=widths, aes(x=mean(c(xbottom[1], xbottom[2], 0)), y=mean(c(ybottom[1], ybottom[2], ybottom[2])), label="theta"), parse=TRUE) +
  coord_equal(ratio=1) + scale_linetype("") + theme(plot.margin = unit(c(-1,-1,-2,-2), "lines"))
@
At the same time, our preference for assessing figure width based on the orthogonal width suggests that the underlying illusion may be a function of geometry rather than some unknown visual or neural process that occurs subconsciously.%, i.e. in the time between perception of the stimulus and conscious thought. 
If this is the case, then it may be  possible to correct the graphical display for the illusion to minimize its misleading effect. A geometrical correction that  --at least temporarily-- counteracts the illusion is be a valuable tool in visual analysis, as this illusion very persistently affects our judgment of very common tasks  such e.g.~the assessment of conditional variability of data along a trend line.
%, we must overcome the visual bias due to the sine illusion. 

Simply raising people's awareness of the presence of this illusion is not enough,
as  this illusion is incredibly difficult to overcome even when we are aware of its presence: our brains simply cannot ``un-see" the illusion. 


What follows is a compilation of several approaches to correct for or mitigate the effect of the illusion, intended primarily to demonstrate how pervasive the illusion is and the extreme measures necessary to remove its effect. 
% do not change this to its'

\section{Breaking the Illusion}
The linewidth  illusion is caused by a conflict between vertical width, which is the width that we want onlookers to assess visually, and orthogonal width, which is the width that the onlooker perceives. This difference can be expressed as a function in the slope of the underlying trend line. This provides the basis for adjusting the vertical width for the perceived orthogonal width. 
%The difference between vertical and orthogonal widths is itself a function of the slope. 
%As such, we can resolve the illusion by adjusting the orthogonal width such that it represents the value that we want the onlooker to perceive. 
We consider the following three approaches:  
\begin{enumerate}
\item separating the trend and the variability, 
\item transformation of $x$: adjusting the slope to be constant by reparametrizing the $x$ axis, and
\item transformation of $y$: adjusting $y$ values to make conditional variability  appear correctly by adjusting accordingto orthogonal width. 
\end{enumerate}
Each of these ideas is discussed in more detail in this section.

\subsection{Trend Removal}
\cite{cleveland:1984, cleveland:1985} discuss the perceptual difficulty of judging the difference between two curves plotted in the same chart, and alternatively, recommend to display the difference between the two curves directly. This is in line with  recommendations  for good graphics to `show the data' rather than make the reader derive some aspect of it \citep[e.g.][]{wainer:2000}. In particular, de-trending data to focus on residual structure is the generally accepted procedure for assessing model fit. 
 Figure \ref{fig:cleveland-figure}(a) shows a scatterplot of data with a trend. A loess smooth is used to estimate the trendline. A visual assessment of variability along this trendline
might result in a description such as `homogeneous variance or slightly increasing variance for  negative $x$, followed by a dramatic decrease in vertical variability for positive $x$'.  
Once the residuals are separated from the trendline as shown on the right hand side of the figure, it becomes apparent that this first assessment of conditional variability was not correct, and the steadily decrease along the horizontal axis becomes visible.
 
While the illusion is not apparent when trend line and variability in the  residual structure are shown separately, this separation  %Removing the trend and showing variability separately does largely remove the sine illusion, but it also 
makes it  more difficult to evaluate the overall  pattern in the data, as we  must base any judgment on two charts; either by combining information from two graphs or by mentally re-composing the original graph (at which point, the sine-illusion becomes a factor). To minimize cognitive demands  we ideally want to tell the whole story with a single graph. 
%Removing the trend in the example is also relatively simple, it is much harder to create a de-trended  version of Figure \ref{fig:playfair-debt} that allows for an easy and accurate assessment of  both the trend and a change in the size of the trade imbalance over time. 


<<cleveland, echo=FALSE, fig.width=6, fig.height=6, include=FALSE>>=
f <- function(x) -x^2
sdf <- function(x) (4-0.5*x)/5
  
x <- seq(-2,2.5, by=0.1)

id <- 1:30
dframe <- expand.grid(x=x, id=id)
dframe$y <- with(dframe, rnorm(n=nrow(dframe), mean=f(x), sd=sdf(x)/2))
qplot(x,y, data=dframe, geom="jitter") + theme_bw()
dframe$Trend <- f(dframe$x)
dframe$Residuals <- dframe$y - dframe$Trend

x <- seq(-2,2.5, by=0.01)
p1 <- qplot(x=x, y=f(x), ylab="Trend", geom="line") + theme_bw()
p2 <- qplot(x=x, y=Residuals, data=dframe, geom="jitter") + theme_bw()
p <- grid.arrange(p1, p2, nrow=2)
p
@
\begin{figure} \hfill
\begin{subfigure}[b]{.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{figure/fig-cleveland1}
  \caption{\small Data}
  \label{fig:clevelandsubfig1}
\end{subfigure} \hfill\hfill
\begin{subfigure}[b]{.45\linewidth}
  \centering
  \includegraphics[width=\textwidth]{figure/fig-cleveland2}
  \caption{\small Trend and Residuals}
  \label{fig:clevelandsubfig2}
\end{subfigure} \hfill
\caption{Describe the conditional variability of the points along the $x$ axis in (a). Is your description consistent with the residual plot in (b)?}
\label{fig:cleveland-figure}
\end{figure}

%From a cognitive perspective, separating out the trendline and the variance creates a barrier to understanding the data in its original form; as the original graph must be mentally re-constructed.
Additionally, removing the trend requires an initial model, making any plots produced using that fit conditional on the assumptions necessary to obtain that model fit. In many situations, this may be undesireable. In particular, we typically view the data before fitting even a rudimentary model, and the sine illusion may influence even these initial modeling decisions.

\subsection{Transformation of the $X$-Axis}
As the sine illusion is driven by the changes in the slope of trends between variables, we can counteract the illusion by removing these changes by transforming the $x$ axis such that the absolute value of the slope is constant. 

This  forces the corresponding orthogonal width to  represent the conditional variability.
In order to describe this transformation of the $x$ axis mathematically, 
let us assume that the relationship between variables $X$ and $Y$ is given by a  model of the form 
\[
y = f(x) + \varepsilon,
\]
where $f$ is some underlying function (either previously known or based on a model fit). Further let us assume that  $f$ is differentiable over the region of observed data.

The idea of correcting for the illusion is to make all lines appear under the same slope, i.e.~we want to find a transformation $T(x)$ of $x$, such that $f(T(x))$ is a  piece-wise linear function, where each piece has the same absolute slope. 

Let $a$ and $b$ be the minimum and maximum of the $x$-range under consideration. Then for any value $x \in (a,b)$ the following transformation results in a function with constant absolute slope (see appendix~\ref{app.xtrans} for a derivation of the equation):
\begin{equation}\label{eqn.xtrans}
(f \circ T)(x) = a + (b-a)\left(\int_{a}^x |f^\prime(z)| dz\right)/\left(\int_{a}^{b}|f^\prime(z)| dz\right),
\end{equation}
 As the sine illusion depends on changing slope in the overall trend,  re-parametrizing the $x$-axis in terms of the slope will make the data  appear under a  constant slope, thereby removing the effect of the illusion, while the transformed $x$-axis is changed from a linear representation of the $x$ values to a `warped' axis that is continuously sped up or lowed down to make up for the changes in the slope.
 To emphasize this change in speed along the $x$ axis,  dots are drawn at  the bottom of the chart  to show the transformation's effect on equally spaced points along the $x$-axis.   

Results from this transformation are demonstrated in Figure \ref{fig:xtrans1}.
%In panel (a),  the $x$-spacing of the lines is transformed according to eqn~(\ref{eqn.xtrans}) and mitigates the sine illusion by changing the extant width such that the absolute value of the slope is uniform across the whole range of the $x$ axis.
 

<<xtransform, echo=FALSE, fig.width=4, fig.height=2, include=FALSE>>=
correctx <- function(z, fprime, a=0, b=2*pi, w=1) {
  # w = 1/(shrink+1)
  const <- integrate(function(x) abs(fprime(x)), a, b)$value
  trans <- sapply(z, function(i) integrate(function(x) abs(fprime(x)), a, i)$value*(b-a)/const + a)
  # alternatively to the rowMeans, you could report back  
  # trans*(1-w) + z*w
  trans*w + z*(1-w)
}
f <- sin
fprime <- cos
f2prime <- function(x) -sin(x)
dframe <- createSine(40 , len=1, f=f, fprime=fprime, f2prime=f2prime)
minor.axis.correction <- correctx(seq(0, 2*pi, pi/8), fprime)

dframe$xtrans <- correctx(dframe$x, fprime=fprime)

dots <- data.frame(x = rep(minor.axis.correction, times=1), y=rep(c(-2), each=length(minor.axis.correction)))

ggplot(aes(x=xtrans, xend=xtrans, y = ystart, yend=yend), data=dframe) +
  geom_abline(aes(slope = 0, intercept=0), colour="grey70") +
  geom_segment(colour="grey20") +
  theme_bw() + coord_fixed(ratio=1) + xlab("x") + ylab("y")+ 
  scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), minor_breaks=minor.axis.correction,
                     labels=c("0", expression(paste(pi,"/2")), expression(pi), expression(paste("3",pi, "/2")), expression(paste("2",pi)))) + 
  geom_point(data=dots, aes(x=x, y=y), inherit.aes=FALSE) + 
  theme(plot.margin = unit(c(.1,.1,-.5,.1), "cm"))

dots$x2 <- correctx(seq(0, 2*pi, pi/8), fprime, w=.5)

dframe$xtrans2 <- correctx(dframe$x, fprime=fprime, w=.5)

ggplot(aes(x=xtrans2, xend=xtrans2, y = ystart, yend=yend), data=dframe) +
  geom_abline(aes(slope = 0, intercept=0), colour="grey70") +
  geom_segment(colour="grey20") +
  theme_bw() + coord_fixed(ratio=1) + 
  xlab("x") + ylab("y")+ 
  scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), minor_breaks=minor.axis.correction,
                     labels=c("0", expression(paste(pi,"/2")), expression(pi), expression(paste("3",pi, "/2")), expression(paste("2",pi)))) + 
  geom_point(data=dots, aes(x=x2, y=y), inherit.aes=FALSE)  + 
  theme(plot.margin = unit(c(.1,.1,-.5,.1), "cm"))

dots$x3 <- correctx(seq(0, 2*pi, pi/8), fprime, w=1/3)

dframe$xtrans3 <- correctx(dframe$x, fprime=fprime, w=1/3)

ggplot(aes(x=xtrans3, xend=xtrans3, y = ystart, yend=yend), data=dframe) +
  geom_abline(aes(slope = 0, intercept=0), colour="grey70") +
  geom_segment(colour="grey20") +
  theme_bw() + coord_fixed(ratio=1) + 
  xlab("x") + ylab("y")+  
  scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), minor_breaks=minor.axis.correction,
                     labels=c("0", expression(paste(pi,"/2")), expression(pi), expression(paste("3",pi, "/2")), expression(paste("2",pi))))+ 
  geom_point(data=dots, aes(x=x3, y=y), inherit.aes=FALSE) + 
  theme(plot.margin = unit(c(.1,.1,-.5,.1), "cm"))

dots$x4 <- correctx(seq(0, 2*pi, pi/8), fprime, w=1/4)

dframe$xtrans4 <- correctx(dframe$x, fprime=fprime, w=1/4)

ggplot(aes(x=xtrans4, xend=xtrans4, y = ystart, yend=yend), data=dframe) +
  geom_abline(aes(slope = 0, intercept=0), colour="grey70") +
  geom_segment(colour="grey20") +
  theme_bw() + coord_fixed(ratio=1) + 
  xlab("x") + ylab("y") +
  scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), minor_breaks=minor.axis.correction,
                     labels=c("0", expression(paste(pi,"/2")), expression(pi), expression(paste("3",pi, "/2")), expression(paste("2",pi))))+ 
  geom_point(data=dots, aes(x=x4, y=y), inherit.aes=FALSE) + 
  theme(plot.margin = unit(c(.1,.1,-.5,.1), "cm"))
@
\begin{figure}[h!tbp]\centering
\begin{subfigure}[b]{.45\linewidth}\centering 
\includegraphics[keepaspectratio=TRUE,width=\linewidth]{figure/fig-xtransform1}
\caption[$X$ axis transformation]{$X$ axis transformation based on eqn.~(\ref{eqn.xtrans}), corresponding to weighting of $w=0$.}
\label{fig:xtrans1}
\end{subfigure} \hfill\hfill
\begin{subfigure}[b]{.45\linewidth}\centering
\includegraphics[keepaspectratio=TRUE,width=\linewidth]{figure/fig-xtransform2} 
\caption[Weighted transformation]{Weighted Transformation, $w=1/2$ (based on eqn.~(\ref{eqn.xtrans.weighted}))}
\label{fig:xtrans2}
\end{subfigure}

\begin{subfigure}[b]{.45\linewidth}\centering 
\includegraphics[keepaspectratio=TRUE,width=\linewidth]{figure/fig-xtransform3}
\caption[Weighted transformation]{Weighted Transformation, $w=1/3$}
\label{fig:xtrans3}
\end{subfigure} \hfill
\begin{subfigure}[b]{.45\linewidth}\centering
\includegraphics[keepaspectratio=TRUE,width=\linewidth]{figure/fig-xtransform4}
\caption[Weighted transformation]{Weighted Transformation, $w=1/4$}
\label{fig:xtrans4}
\end{subfigure}
\caption[X axis transformations]{Examples of $X$ axis transformations in the sine curve.  Dots at the bottom of the graph show the transformation's effect on equally spaced points along the $x$-axis. Different amounts of weighting $w$ correspond to differently strong corrections. In (a),   $x$-spacing of the lines changes the extant width such that the absolute value of the slope is uniform across the whole range of the $x$ axis resulting in the largest amount of correction.  (b) - (d) reduce the correction in (a) towards successively more uniform spacings in $x$ while still breaking the effects of the illusion.}
\label{fig:xtrans}
\end{figure}
While the transformation in equation (\ref{eqn.xtrans}) effectively removes the appearance of changing line lengths, we can see in practice that the illusion can be broken by a much less severe transformation of the $x$ axis. 
For that we introduce a shrinkage factor $w \in (0,1)$ that allows a weighted approach in counteracting the illusion as: 
%
\begin{equation}\label{eqn.xtrans.weighted}
(f \circ T_w)(x) = (1-w) \cdot x + w \cdot (f \circ T)(x)
\end{equation}
%
Note that for $w=1$ the $x$-transformation is completely warped, while smaller values of $w$ indicate a less severe adjustment against the sine illusion.  Under  weaker transformation,s the data more closely reflect the original function $f(x)$. 
Figures \ref{fig:xtrans2} - \ref{fig:xtrans4} show the effect of different shrinkage coefficients $w$. As $w$ decreases, the lines become more evenly spaced and the illusion begins to return. %The dots at the bottom of each plot indicate evenly spaced x-axis points that have been transformed; as $w$ decreases, the dots become more evenly spaced. 

The extent  to which we can shrink the adjustment back to the original function  varies with the aspect ratio of the chart and the shape of the function. It might also be influenced by the audience's experience with the sine illusion, resulting in very subjective choices of an
%, but merits further investigation, as it may be possible to find an 
``optimal weighting" for specific situations which minimizes distortion and maximizes the correspondence between inferences made from the data and inferences made using the visual display.
%\comment{I'm not sure we want to say it depends on the audience's experience - I suspect that people with experience are more likely to use a "when do I no longer see it" approach, rather than a "when do I see it approach", i.e. looking at the limit from 0->1 instead of the more naive approach of 1->0. We might want to do a short experiment involving "yes or no" tests instead of graduated approaches - say, 3 plots of x, 3 plots of y, 3 distractor plots for each subject. We could probably just mix this into the shiny experiment... }

Note, that we only make use of the transformation $T$ in the form of $f \circ T$. This allows us to avoid an explicit calculation of the transformation $T$, which in particular  involves a computation of the inverse of $f$ leading to potentially computationally  very intensive solutions. 

%\FloatBarrier
%\clearpage
<<xtrans-example, echo=FALSE, include=FALSE, dependson='xtransform', fig.width=6, fig.height=6>>=
library(locfit)

datasub <- read.csv("data/Ozone/Ozone-subset.csv")
model <- locfit(data=datasub, Ozone~Tmax)
deriv <- locfit(data=datasub, Ozone~Tmax, deriv=1)

f <- function(x) predict(model, newdata=data.frame(Tmax=x))
fprime <- function(x) predict(deriv, newdata=data.frame(Tmax=x))

datasub$TmaxCorrect <- correctx(datasub$Tmax, fprime, a=45, b=95, w=1)
datasub$TmaxCorrect2 <- correctx(datasub$Tmax, fprime, a=45, b=95, w=1/2)


dots <- data.frame(Tmax=seq(45, 95, length=11), Ozone=0)
dots$TmaxCorrect <- correctx(dots$Tmax, fprime, a=45, b=95, w=1)
dots$TmaxCorrect2 <- correctx(dots$Tmax, fprime, a=45, b=95, w=1/2)

breaks <- data.frame(labels=as.character(seq(50, 90, 5)), breaks=seq(50, 90, 5))
breaks$breaks1 <- correctx(breaks$breaks, fprime, a=45, b=95, w=1)
breaks$breaks2 <- correctx(breaks$breaks, fprime, a=45, b=95, w=1/2)

nsite <- length(unique(datasub$SiteID))

qplot(data=datasub, x=Tmax, y=Ozone, geom="jitter", colour=I("grey30"), alpha=I(.5), 
      xlab="Temperature (F)", ylab="8-hour Average Ozone Concentration (ppm)") + 
  geom_line(aes(x=Tmax, y=fit), size=1.25, colour="steelblue") + theme_bw()+ 
  geom_point(data=dots, aes(x=Tmax))
qplot(data=datasub, x=TmaxCorrect, y=Ozone, geom="jitter", colour=I("grey20"), alpha=I(.5), 
      xlab="Temperature (F)", ylab="8-hour Average Ozone Concentration (ppm)") + 
  geom_line(aes(x=TmaxCorrect, y=fit), size=1.25, colour="steelblue") + theme_bw() + 
  geom_point(data=dots) + 
  scale_x_continuous(breaks=breaks$breaks1, minor_breaks=dots$TmaxCorrect, labels=breaks$labels) 
qplot(data=datasub, x=TmaxCorrect2, y=Ozone, geom="jitter", colour=I("grey20"), alpha=I(.5), 
      xlab="Temperature (F)", ylab="8-hour Average Ozone Concentration (ppm)") + 
  geom_line(aes(x=TmaxCorrect2, y=fit), size=1.25, colour="steelblue") + theme_bw() + 
  geom_point(data=dots) + 
  scale_x_continuous(breaks=breaks$breaks2, minor_breaks=dots$TmaxCorrect, labels=breaks$labels)

@

In the example of the Ozone data shown in Figure \ref{fig:exampleFull1}, we can base a transformation of the $x$-axis on a loess fit of ozone concentration in daily temperature. Loess is particularly convenient for this transformation, as it enforces continuity conditions including differentiability of the fitted function; software allows us to obtain fits of both the function values and their derivatives.
%the fitted $f^\prime(x)$ as well as $f(x)$. 
Figure \ref{fig:xtrans-example} shows the original data side-by-side with the transformed $x$-axis.
%
\begin{figure}[h!]\centering
\begin{subfigure}[b]{.48\linewidth}\centering
\includegraphics[keepaspectratio=TRUE,width=\linewidth]{figure/fig-xtrans-example1}
\caption{Original Data}\label{fig:xtrans-example-original}
\end{subfigure}
\begin{subfigure}[b]{.48\linewidth}\centering
\includegraphics[keepaspectratio=TRUE,width=\linewidth]{figure/fig-xtrans-example2}
\caption{Transformed $X$ Axis}\label{fig:xtrans-example-trans}
\end{subfigure}
\caption{Original data and data after $x$-transformation. The increasing variance is easier to see when $x$ has been transformed, because the slope is now uniform.\label{fig:xtrans-example}}
\end{figure}
Figure \ref{fig:xtrans-example} demonstrates not only the effect of transformation of the $x$-axis, but also that the transformation is not particularly misleading in this example.The granularity of the data in this example provides an implicit measure of the strength of the transformation along the $x$-axis and the transformation is also clearly evident in the labels along the $x$-axis. 
% While we typically prefer that our axis transformations are monotone, this transformation provides additional utility that a monotone transformation does not. \newdo{ the transformation is monotone - it only goes up and doesn't reverse the temperatures. it's even continuous, but it is not differentiable. }
% 
% \todo[inline]{add more explanation, etc here so that it's not orphaned.}
\subsection{Transformation in $Y$}
Understanding the geometry of the sine illusion leads to another approach to counteracting  the conflict between the orthogonal width and the vertical length of the segment. 

%All of our approaches in this section are based on a comparison of the orthogonal width to the vertical length of lines. 
%%Studies have shown \cite{XXX, YYY} that onlookers generally evaluate orthogonal width rather than vertical or horizontal widths of lines.
%By adjusting the vertical width in such a way that the (perceived) orthogonal width displays the quantity of interest, we can match an onlooker's intuitive evaluation of a situation  with the data values we want to present.
%
%% 
%
%\begin{SCfigure}
%\centering
%% \includegraphics[width=0.3\linewidth]{images/linewidth}
%\includegraphics[width=.35\linewidth]{figure/fig-geometry}
%\caption{Sketch of line width assessments: The solid line shows vertical width, the dotted line shows  width orthogonal to the slope. \label{fig:linewidth}}
%\end{SCfigure}
%
%As Figure \ref{fig:linewidth} shows, orthogonal $w_o$ and vertical $w_v$ line widths are related -- the orthogonal line width depends on the angle under which the line is drawn. Mathematically, we have:
%\begin{equation}\label{eqn.adjust}
%w_o = w_v \cos \theta,
%\end{equation}
%where $\theta$ is the acute angle between the orthogonal line and the vertical, that is, $\theta \in (-\pi, \pi]$. The relationship between $\theta$ and extant width for $y = \sin(x)$ can be seen in Figure~\ref{fig:OrthogonalWidth}.


%Figure \ref{fig:linewidth} shows a more simplified illustration of $\theta$, the angle of the orthogonal line to the vertical. 

% \subsubsection{Trigonometry Method}\label{trig}
% 
% 
% 
% The approach that we take here is sketched out in figure \ref{fig:trig}: 
% we evaluate the slope of function $f$ in position $x$, find an approximation of the extant width as $m = \ell \cos{\theta}$, and adjust $\ell$ based on the ratio of vertical and extant width. The corresponding angle $\theta$ is determined by the slope of function $f$ in $x$, i.e.
% %
% <<trigmethodcartoon,echo=FALSE, include=FALSE, cache=FALSE>>=
% f <- function(x) 2*sin(x)
% fprime <- function(x) 2*cos(x)
% f2prime <- function(x) -2*sin(x)
% df <- createSine(40 , len=1, f=f, fprime=fprime, f2prime=f2prime)[5:16,]
% a <- 9
% dfsec <- getSecantSegment(df$x[a], df=df, f, fprime, f2prime)
% dfslope <- data.frame(xstart=df$x[a]+.5, xend=df$x[a]-.9, ystart=fprime(df$x[a])*.5+df$y[a], yend=-.9*fprime(df$x[a])+df$y[a])
% dfslope2 <- data.frame(xstart=df$x[a]+.5, xend=df$x[a]-.3, ystart=fprime(df$x[a])*.5+df$y[a]+.5, yend=-.3*fprime(df$x[a])+df$y[a]+.5)
% ftsize <- 4
% 
% df <- createSine(40 , len=1, f=f, fprime=fprime, f2prime=f2prime)[5:16,]
% 
% a <- 9
% df.real <- data.frame(x=seq(df$x[1], df$x[12], by=.001))
% df.real$y <- f(df.real$x)
% df.real$yupper <- fprime(df$x[a])*(df.real$x-df$x[a])+f(df$x[a])+.5
% df.real$yupper[which(abs(df.real$x-2)>.5)] <- NA
% df.real$ylower <- fprime(df$x[a])*(df.real$x-df$x[a])+f(df$x[a])-.5
% df.real$ylower[which(abs(df.real$x-2)>.5)] <- NA
% df.real$sec <- -1/fprime(df$x[a])*(df.real$x-df$x[a])+f(df$x[a])
% df.real$sec[which(abs(df.real$x-2)>.5)] <- NA
% dfslope <- data.frame(xstart=df$x[a]+.5, xend=df$x[a]-.9, ystart=fprime(df$x[a])*.5+df$y[a], yend=-.9*fprime(df$x[a])+df$y[a])
% dfslope2 <- data.frame(xstart=df$x[a]+.5, xend=df$x[a]-.3, ystart=fprime(df$x[a])*.5+df$y[a]+.5, yend=-.3*fprime(df$x[a])+df$y[a]+.5)
% 
% cairo_pdf("./figure/fig-trigmethodcartoon.pdf", width=5, height=5)
% qplot(data=df.real, x=x, y=y, geom="line") +
%   theme(panel.grid.major=element_blank(), 
% #      panel.background = element_rect(fill = "white", colour = "black"),
%       panel.background=element_blank(),  
%       panel.grid.minor=element_blank(),
%       axis.title = element_blank(), axis.ticks = element_blank(), 
%       axis.text = element_blank()) +  
%   coord_equal(ratio=1) +
%   geom_line(data=df.real,aes(y=yupper), linetype=3) + 
%   geom_line(data=df.real,aes(y=ylower), linetype=4) + 
%   geom_segment(data=df, aes(x=xstart, y=ystart, xend=xend, yend=yend), colour="grey50") + 
%   geom_segment(data=df[a,], aes(x=xstart, y=ystart, xend=xend, yend=yend), colour="black", size=1.5)+
%   geom_line(data=df.real, aes(y=sec)) + 
%   geom_text(data=dfslope, aes(x=xend+.1, y=yend+.05, label="slope: paste(f, \"'\", (x))"), parse=TRUE, hjust=0, vjust=1) +
%   geom_text(aes(x=mean(c(dfsec$sec.xstart, df$xend[a], df$x[a], df$x[a])), 
%                 y=mean(c(dfsec$sec.ystart, df$yend[a], df$y[a], df$y[a]))-.25 
%                 ), label="theta", parse=TRUE, size=ftsize+1, data=data.frame()) +
%   geom_text(aes(x=df.real$x[which.min(df.real$sec)], y=min(df.real$sec, na.rm=TRUE)-.05), 
%                 label="slope: paste(-1/f, \"'\", (x))", parse=TRUE, hjust=.75, vjust=1, data=data.frame()) +
%   geom_text(data=df[a,], aes(x=.5*xend-.075 + .5*x, y=.5*yend+.5*y+0.05, label="paste(frac(\u2113, 2))"), size=ftsize+1, face="bold", parse=TRUE) +
%   geom_text(aes(x=.5*dfsec$sec.xstart+ .5*dfsec$x +.33 , y=.5*dfsec$sec.ystart+.5*dfsec$y+0.225), label="paste(frac(m, 2))", parse=TRUE, face="plain", data=data.frame()) + 
%   xlab("x") + ylab("y") +
%   geom_segment(data=dfslope, aes(x=xstart, y=ystart, xend=xend, yend=yend), linetype=2) + theme(axis.title=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.line=element_blank(), panel.grid=element_blank())
% dev.off()
% @
% \begin{SCfigure}
% \centering
% \includegraphics[keepaspectratio=TRUE,width=.5\linewidth]{figure/fig-trigmethodcartoon}
% \caption[Geometry of the trig correction approach]{Geometry of the trigonometry correction approach. $\ell$ denotes the length of the  vertical segment, $m$ is the extant width, $\theta$ denotes the angle between the line segments.
% \label{fig:trig}}
% \end{SCfigure}
% % 
% % Our goal is to make the segment $m$ appear as long as the segment $\ell$. As the angle $\theta$ is determined by the slope of the tangent line, that is, 
% $$\tan \theta = \left|f^\prime(x)\right|.$$ 
% Solving for $\theta$ leaves us with a ratio of orthogonal and vertical width of 
% $$\left[\cos(\atan{\left|f^\prime(x)\right|})\right]^{-1} = \ell/m.$$ 
% 
% That is, we have to scale $\ell$ by a factor of 
% $\left[\cos(\atan{\left|f^\prime(x)\right|})\right]^{-1}$
% to make the extant width $m$ appear as long as $\ell$ in the original graph: 
% % We first multiply the vertical width by a factor of $1/\cos\theta$, where $\theta$ is the angle under which the line is drawn. This angle is given by the slope of the function, mathematically we know that in position $x$ the angle $\theta(x)$ of function $f(x)$ is given as:
% % \[
% % \tan \theta (x) = f^\prime (x).
% % \]
% % We only distinguish the size, not the sign of the angle, which gives us an overall correction factor for the line width in vertical direction of 
% \begin{equation}\label{trigCorrection}
% \ell_{\text{new}} = \ell\cdot\left(\cos\left[\atan{\left| f^\prime (x) \right|}\right]\right)^{-1} = \ell \cdot \sqrt{1 + |f^\prime(x)^2|}
% \end{equation}
% The last equality follows directly when using $y = \atan{|f^\prime(x|}$ in the formula below:
% \begin{eqnarray*}
% \cos(y) = 1/\text{sec}(y) = 1/\sqrt{1+ \tan^2 y}.\\
% \end{eqnarray*}
% 
 <<trigFix, echo=FALSE, include=FALSE, fig.width=4, fig.height=3>>=
dframe <- createSine(40,1, f=f, fprime=fprime, f2prime=f2prime)
 qplot(x=x, xend=xend, y = f(x) -ell/2, yend=f(x) +ell/2, geom="segment", data=dframe) +
   theme(panel.background=element_blank(), axis.title = element_blank()) + 
   coord_equal(ratio=1)+ 
   xlab("x") + ylab("y") +
   scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), minor_breaks=minor.axis.correction,
                      labels=c("0", expression(paste(pi,"/2")), expression(pi), expression(paste("3",pi, "/2")), expression(paste("2",pi))))
  
 qplot(x=x, xend=xend, y = f(x) -ellx/2, yend=f(x) +ellx/2, geom="segment", data=dframe) +
   theme(panel.background=element_blank(), axis.title = element_blank()) + 
   coord_equal(ratio=1)+ 
   xlab("x") + ylab("y") +
   scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), minor_breaks=minor.axis.correction,
                      labels=c("0", expression(paste(pi,"/2")), expression(pi), expression(paste("3",pi, "/2")), expression(paste("2",pi))))
  
#  
#  qplot(x=x, xend=xend, y = f(x) -ellx2/2, yend=f(x) +ellx2/2, geom="segment", data=dframe) +
#    theme(panel.background=element_blank(), axis.title = element_blank()) + 
#    coord_equal(ratio=1)+ 
#    xlab("x") + ylab("y") +
#    scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), minor_breaks=minor.axis.correction,
#                       labels=c("0", expression(paste(pi,"/2")), expression(pi), expression(paste("3",pi, "/2")), expression(paste("2",pi)))) 
 @
% \begin{figure}[h!btp]
% \begin{subfigure}[b]{.48\linewidth}\centering
% \includegraphics[width=\linewidth,keepaspectratio=TRUE]{figure/fig-trigFix1}
% \caption{Uncorrected}
% \end{subfigure}
% \begin{subfigure}[b]{.48\linewidth}\centering
% \includegraphics[width=\linewidth,keepaspectratio=TRUE]{figure/fig-trigFix2}
% \caption{Trigonometric correction}
% \end{subfigure}
% \caption[Demonstration of Trig Correction Fix]{\label{fig:trigFix} 
% Fix of the sine illusion by using the factor of $1/\cos\left(\atan{|\cos(x)|}\right)$ to adjust the vertical extent of the lines.}
% \end{figure}
% 
% The correction is shown in Figure \ref{fig:trigFix}. 
% The assumption underlying this correction is the existence of a differentiable function $f$ describing the relationship between $X$ and $Y$,
%  as the correction is based on the slope of the orthogonal line given by $-1/f^\prime(x)$.
% 
% \comment{The correction factor seems to over-correct. Is this just something that happens to the trained eye? We might need people to test for it.\\ I agree, because it looks a bit overcorrected to me as well.}
% 
% \subsubsection{A General Correction Method}
Let again the function $f$ describe the general relationship between variables $X$ and $Y$. 


As sketched out in figure~\ref{fig:GeneralCorrection} we want to first find the orthogonal (extant) width in a point $(x_0, f(x_o))$ on the graph, which corresponds to the  perceived width, and then correct the vertical width accordingly to match with the audience's expectation.

\begin{SCfigure}
\centering
\includegraphics[keepaspectratio=TRUE,width=.4\linewidth]{figure/fig-generalcorrectioncartoon3}
\caption[General correction approach]{ General correction approach. This approach may require numerical optimization to obtain exact solutions for $(x_1, y_1)$ and $(x_2, y_2)$.}\label{fig:GeneralCorrection}
\end{SCfigure}

The orthogonal width is given as the line segment between endpoints $(x_1, f_1(x_1))$ and $(x_2, f_2(x_2))$, where $f_1$ and $f_2$ denote the vertical shifts of function $f$ by $-\ell/2$ and $\ell/2$, respectively.
These endpoints are determined as the intersection of the line  orthogonal to the tangent line in $(x, f(x))$ and the graphs resulting from vertical shifts of $f$ by $\pm \ell/2$.

The function describing the orthogonal line through $(x_o, f(x_o))$ is given in point-vector form as 
\[
{x_o \choose f(x_o)} + \lambda {f^\prime(x_o) \choose 1}, 
\]
for any real-valued $\lambda$.
The advantage of using point vector form is that it allows us to solve for parameter $\lambda$ easily, which gives us easy access to the extant (half-)widths, which are given as 
\[
|\lambda| \sqrt{1 + f^\prime(x_o)^2}.
\]
This expression describes the quantity that we perceive rather than the quantity that we want to display ($\ell/2$), which leads us to a general expression of the correction factor as
\begin{eqnarray*}
 \ell/2 \cdot \left(|\lambda| \sqrt{1 + f^\prime(x_o)^2}\right)^{-1}.
\end{eqnarray*}
Note that this yields in general two solutions: one for positive, one for negative values of $\lambda$ corresponding to upper and lower (half-)extant width.

In order to get  actual numeric values for $\lambda$, we need to find end points of the extant line width as solutions of intersecting the orthogonal line and  the graphs of $f_1$ and $f_2$. We find these end points  as solutions in $x$ and $\lambda$ of the system of equations:
\begin{eqnarray}\label{eqn.general}
 x - x_o &=& \lambda f^\prime(x_o)\\ \label{eqn.general.2}
 f(x) - f(x_o) &=& -\lambda \pm \ell/2
\end{eqnarray}


Note that  the above system of equations involves function values $f(x)$, which implies that solving this system  requires numerical optimization for any but the most simple functions $f$.

In the following two sections we are going to use Taylor approximations of first and second order to find approximate solutions to the end points.


% 
% As shown in Figure \ref{GeneralCorrection}, another method for adjusting the vertical length to ensure constant extant width is to solve the systems of equations\\
% \begin{minipage}[t]{.495\linewidth}
% \begin{align*}
% y_2 & = f(x_2) + \ell/2\\
% y_2 & = \left(-1/f^\prime(x_0)\right) x_2 + f(x_0) + x_0/f^\prime(x_0)
% \end{align*}\vspace{8pt}
% \end{minipage}
% \begin{minipage}[t]{.495\linewidth}
% \begin{align*}
% y_l & = f(x_l) - \ell/2\\
% y_l & = \left(-1/f^\prime(x_0)\right) x_l + f(x_0) + x_0/f^\prime(x_0)
% \end{align*}
% \end{minipage}\\
% to obtain  $(x_2,y_2)$, the point at which the orthogonal line intersects $f(x) + \ell/2$, and $(x_l, y_l)$, thet point at which the orthogonal line intersects $f(x) -\ell/2$. With these two endpoints, we can correct separately for the top and bottom portions of the line, as the extant width is not symmetric when reflected across the original function f(x). 


<<generalcorrectioncartoon,echo=FALSE, include=FALSE, fig.width=4, fig.height=4>>=
f <- function(x) 2*sin(x)
fprime <- function(x) 2*cos(x)
f2prime <- function(x) -2*sin(x)
df <- createSine(40 , len=1, f=f, fprime=fprime, f2prime=f2prime)[5:16,]

a <- 9
df.real <- data.frame(x=seq(df$x[1], df$x[12], by=.001))
df.real$y <- f(df.real$x)
df.real$yupper <- df.real$y+.5
df.real$ylower <- df.real$y-.5
dfsec <- getSecantSegment(df$x[a], df, f, fprime, f2prime)
dfslope <- data.frame(xstart=df$x[a]+.5, xend=df$x[a]-.9, ystart=fprime(df$x[a])*.5+df$y[a], yend=-.9*fprime(df$x[a])+df$y[a])
dfslope2 <- data.frame(xstart=df$x[a]+.5, xend=df$x[a]-.3, ystart=fprime(df$x[a])*.5+df$y[a]+.5, yend=-.3*fprime(df$x[a])+df$y[a]+.5)
qplot(data=df.real, x=x, y=y, geom="line") + 
  theme(panel.grid.major=element_blank(), 
        panel.grid.minor=element_blank(), panel.background=element_blank(),
        axis.title = element_blank(), axis.ticks = element_blank(), 
        axis.text = element_blank()) +  
  geom_line(data=df.real,aes(y=yupper), linetype=3) + 
  geom_line(data=df.real,aes(y=ylower), linetype=4) + 
  geom_segment(data=df, aes(x=xstart, y=ystart, xend=xend, yend=yend), colour="grey50") + 
  geom_segment(data=df[a,], aes(x=xstart, y=ystart, xend=xend, yend=yend), colour="black", size=1.5)+
  geom_segment(data=dfsec, aes(x=sec.xstart, xend=sec.xend, y=sec.ystart, yend=sec.yend)) + 
  geom_point(data=dfsec, aes(x=sec.xstart, y=sec.ystart)) + geom_point(data=dfsec, aes(x=sec.xend, y=sec.yend)) +
  geom_segment(data=dfslope, aes(x=xstart, y=ystart, xend=xend, yend=yend), linetype=2) + 
  geom_text(data=dfsec, aes(x=sec.xstart, y=sec.ystart+.05, label="paste(group('(',list(x[2],y[2]),')'))"), parse=TRUE, hjust=0) + 
  geom_text(data=dfsec, aes(x=sec.xend, y=sec.yend-.08, label="paste(group('(',list(x[1],y[1]),')'))"), parse=TRUE, hjust=.9) +   
  geom_text(data=dfslope, aes(x=xend+.1, y=yend+.1, label="slope: paste(f, \"'\", (x))"), parse=TRUE, hjust=.75, vjust=1) +
  coord_equal(ratio=1) + theme(axis.title=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.line=element_blank(), panel.grid=element_blank(), plot.margin = unit(c(-1,-1,-2,-2), "lines")) 

df <- createSine(40 , len=1, f=f, fprime=fprime, f2prime=f2prime)[5:16,]

a <- 9
df.real <- data.frame(x=seq(df$x[1], df$x[12], by=.001))
df.real$y <- f(df.real$x)
df.real$yupper <- fprime(df$x[a])*(df.real$x-df$x[a])+f(df$x[a])+.5
df.real$yupper[which(abs(df.real$x-2)>.5)] <- NA
df.real$ylower <- fprime(df$x[a])*(df.real$x-df$x[a])+f(df$x[a])-.5
df.real$ylower[which(abs(df.real$x-2)>.5)] <- NA
df.real$sec <- -1/fprime(df$x[a])*(df.real$x-df$x[a])+f(df$x[a])
df.real$sec[which(abs(df.real$x-2)>.5)] <- NA
df.real$sec[which(df.real$sec>df.real$yupper | df.real$sec<df.real$ylower)] <- NA
dfslope <- data.frame(xstart=df$x[a]+.5, xend=df$x[a]-.9, ystart=fprime(df$x[a])*.5+df$y[a], yend=-.9*fprime(df$x[a])+df$y[a])
dfslope2 <- data.frame(xstart=df$x[a]+.5, xend=df$x[a]-.3, ystart=fprime(df$x[a])*.5+df$y[a]+.5, yend=-.3*fprime(df$x[a])+df$y[a]+.5)
qplot(data=df.real, x=x, y=y, geom="line")+
  theme(panel.grid.major=element_blank(), 
        panel.grid.minor=element_blank(), panel.background=element_blank(),
        axis.title = element_blank(), axis.ticks = element_blank(), 
        axis.text = element_blank(),
        plot.margin = unit(rep(0,4), "lines")) +
  coord_equal(ratio=1) +
  geom_line(data=df.real,aes(y=yupper), linetype=3) + 
  geom_line(data=df.real,aes(y=ylower), linetype=4) + 
  geom_segment(data=df, aes(x=xstart, y=ystart, xend=xend, yend=yend), colour="grey50") + 
  geom_segment(data=df[a,], aes(x=xstart, y=ystart, xend=xend, yend=yend), colour="black", size=1.5)+
  geom_line(data=df.real, aes(y=sec)) + 
  geom_point(data=df.real[which.min(df.real$sec),], aes(x=x, y=sec), size=2) + 
  geom_point(data=df.real[which.max(df.real$sec),], aes(x=x, y=sec), size=2) +
  geom_segment(data=dfslope, aes(x=xstart, y=ystart, xend=xend, yend=yend), linetype=2) + 
  geom_text(data=df.real[which.min(df.real$sec),], aes(x=x, y=sec-0.08, label="paste(group('(',list(x[1],y[1]),')'))"), 
            parse=TRUE, hjust=1, vjust=.25) + 
  geom_text(data=df.real[which.max(df.real$sec),], aes(x=x-.05, y=sec+.05, label="paste(group('(',list(x[2],y[2]),')'))"), 
            parse=TRUE, hjust=0, vjust=.25)  + 
  theme(axis.title=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.line=element_blank(), panel.grid=element_blank())


df <- createSine(40 , len=1, f=f, fprime=fprime, f2prime=f2prime)[5:16,]

a <- 9
df.real <- data.frame(x=seq(df$x[1], df$x[12], by=.001))
df.real$y <- f(df.real$x)
df.real$yupper <- .5*f2prime(df$x[a])*(df.real$x-df$x[a])^2 + fprime(df$x[a])*(df.real$x-df$x[a])+f(df$x[a])+.5
df.real$yupper[which(abs(df.real$x-2)>.5)] <- NA
df.real$ylower <- .5*f2prime(df$x[a])*(df.real$x-df$x[a])^2 + fprime(df$x[a])*(df.real$x-df$x[a])+f(df$x[a])-.5
df.real$ylower[which(abs(df.real$x-2)>.5)] <- NA
df.real$sec <- -1/fprime(df$x[a])*(df.real$x-df$x[a])+f(df$x[a])
df.real$sec[which(abs(df.real$x-2)>.5)] <- NA
df.real$sec[which(df.real$sec>df.real$yupper | df.real$sec<df.real$ylower)] <- NA
dfslope <- data.frame(xstart=df$x[a]+.5, xend=df$x[a]-.9, ystart=fprime(df$x[a])*.5+df$y[a], yend=-.9*fprime(df$x[a])+df$y[a])
dfslope2 <- data.frame(xstart=df$x[a]+.5, xend=df$x[a]-.3, ystart=fprime(df$x[a])*.5+df$y[a]+.5, yend=-.3*fprime(df$x[a])+df$y[a]+.5)
qplot(data=df.real, x=x, y=y, geom="line") + 
  theme(panel.grid.major=element_blank(), 
        panel.grid.minor=element_blank(), panel.background=element_blank(),
        axis.title = element_blank(), axis.ticks = element_blank(), 
        axis.text = element_blank(),
        plot.margin = unit(rep(0,4), "lines")) +  
  coord_equal(ratio=1) +
  geom_line(data=df.real,aes(y=yupper), linetype=3) + 
  geom_line(data=df.real,aes(y=ylower), linetype=4) + 
  geom_segment(data=df, aes(x=xstart, y=ystart, xend=xend, yend=yend), colour="grey50") + 
  geom_segment(data=df[a,], aes(x=xstart, y=ystart, xend=xend, yend=yend), colour="black", size=1.5)+
  geom_line(data=df.real, aes(y=sec)) + 
  geom_point(data=df.real[which.min(df.real$sec),], aes(x=x, y=sec), size=2) + 
  geom_point(data=df.real[which.max(df.real$sec),], aes(x=x, y=sec), size=2) +
  geom_segment(data=dfslope, aes(x=xstart, y=ystart, xend=xend, yend=yend), linetype=2) + 
  geom_text(data=df.real[which.min(df.real$sec),], aes(x=x, y=sec-0.08, label="paste(group('(',list(x[1],y[1]),')'))"), 
            parse=TRUE, hjust=1, vjust=.25) + 
  geom_text(data=df.real[which.max(df.real$sec),], aes(x=x-.05, y=sec+.05, label="paste(group('(',list(x[2],y[2]),')'))"), 
            parse=TRUE, hjust=0, vjust=.25)  + 
  theme(axis.title=element_blank(), axis.text=element_blank(), axis.ticks=element_blank(), axis.line=element_blank(), panel.grid=element_blank())
@


\begin{figure}[h!]\centering
\begin{subfigure}[t]{0.495\textwidth}\centering
\includegraphics[keepaspectratio=TRUE,width=0.9\textwidth]{figure/fig-generalcorrectioncartoon2}
\caption{Linear Approximation}\label{fig:linear-GeneralCorrection}
\end{subfigure}
\begin{subfigure}[t]{0.495\textwidth}\centering
\includegraphics[keepaspectratio=TRUE,width=0.9\textwidth]{figure/fig-generalcorrectioncartoon3}
\caption{Quadratic Approximation}\label{fig:quadratic-GeneralCorrection}
\end{subfigure}
\caption[Methods based on Approximations to f(x)]{(a) uses a first-order Taylor series approximation to $f(x)$ and (b) uses a second-order Taylor series approximation to $f(x)$. The intersection of the function $f(x) \pm \ell/2$ and the orthogonal line,  $(x_1, y_1), (x_2, y_2)$ must be obtained to determine the necessary correction factor.}\label{fig:linear.quadratic} 
\end{figure}

\paragraph{Linear Approximation to $f(x)$}\hfill\newline
For the linear approximation we make use of $f(x) \approx f(x_0) + (x - x_0) f^\prime(x_0)$, which together with  equations~\ref{eqn.general} and \ref{eqn.general.2} yields a correction factor in $x_0$ of
\[
\ell_{\text{new}} = \ell_{\text{old}} \sqrt{1 +  f^\prime(x_0)^2}.
\]
% A comparison of the sketches for the linear approach (in Fig. \ref{fig:linear-GeneralCorrection}) and the trigonometric approach (in Fig. \ref{fig:trig}) shows that they are the same. They do, indeed, lead to the same correction factor.
% 
Note that the linear method yields the same result as a varying slope extension from a trigonometric approach as suggested by \citet{schonlau:2003} and used in \citet{marie:2013}
%Previous work in \citet{schonlau:2003, marie:2013} used the adjustment in eqn.~(\ref{eqn.adjust}) for a line with constant slope. We have to extend this approach to a functional form with varying slope. This is the approach taken in the next sections.

The asymmetric nature of the distortion suggests that we may want to use a second-order Taylor polynomial approximation to $f(x)$ to account for the asymmetry in the extant widths on either side of the center trendline.

\paragraph{Quadratic Approximation to $f(x)$}\hfill\newline
%
Using the approximation $f(x) \approx f(x_0) + f^\prime(x_0)(x-x_0) + 1/2 f^{\prime\prime}(x_0)(x-x_0)^2$, the system of equations~\ref{eqn.general} and~\ref{eqn.general.2}  simplifies to the following  quadratic equation in $\lambda$:
\begin{eqnarray*}
f^{\prime\prime}(x_0)  f^\prime(x_0)^2 \lambda^2  + 2(f^\prime(x_0)^2 + 1) \lambda  \pm \ell = 0,
\end{eqnarray*}
which leads us to corrections for the half lengths as (see appendix \ref{app.quadratic} for details):
\begin{eqnarray}\label{eqn.q1}
\ell_{\text{new}_1} &=& 1 /2 \cdot  \left(v + \sqrt{ v^2 +  f^{\prime\prime}(x_0) f^\prime(x_0)^2\cdot  \ell_{\text{old}}}\right) \cdot v^{-1/2} \\\label{eqn.q2}
\ell_{\text{new}_2} &=& 1 /2 \cdot  \left(v + \sqrt{ v^2 -  f^{\prime\prime}(x_0) f^\prime(x_0)^2\cdot  \ell_{\text{old}}}\right) \cdot v^{-1/2} 
\end{eqnarray}
where $v = 1 + f^\prime(x_0)^2$.
\begin{figure}[h!btp]
\begin{subfigure}[b]{.3\linewidth}\centering
<<UncorRresults, echo=FALSE, fig.width=4, fig.height=3, out.width='\\linewidth'>>=
dframe <- createSine(40,1, f=f, fprime=fprime, f2prime=f2prime)
 qplot(x=x, xend=xend, y = f(x) -ell/2, yend=f(x) +ell/2, geom="segment", data=dframe) +
   theme(panel.background=element_blank(), axis.title = element_blank()) + 
   coord_equal(ratio=1)+ 
   xlab("x") + ylab("y") +
   scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), minor_breaks=minor.axis.correction,
                      labels=c("0", expression(paste(pi,"/2")), expression(pi), expression(paste("3",pi, "/2")), expression(paste("2",pi))))
@
\caption{Uncorrected}
\end{subfigure}
\begin{subfigure}[b]{.3\linewidth}\centering
% \includegraphics[width=\linewidth,keepaspectratio=TRUE]{figure/fig-trigFix2}
<<LinearResults,echo=FALSE, fig.width=4, fig.height=3, out.width='\\linewidth'>>=
dframe <- createSine(40,1, f=f, fprime=fprime, f2prime=f2prime)
 qplot(x=x, xend=xend, y = f(x) -ellx/2, yend=f(x) +ellx/2, geom="segment", data=dframe) +
   theme(panel.background=element_blank(), axis.title = element_blank()) + 
   coord_equal(ratio=1)+ 
   xlab("x") + ylab("y") +
   scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), minor_breaks=minor.axis.correction,
                      labels=c("0", expression(paste(pi,"/2")), expression(pi), expression(paste("3",pi, "/2")), expression(paste("2",pi))))
@
\caption{Linear correction}
\end{subfigure}
%
\begin{subfigure}[b]{.3\linewidth}\centering
<<CtsAdjustedResults,echo=FALSE, dependson='CtsQuadratic', fig.width=4, fig.height=3, out.width='\\linewidth'>>=
dframe <- createSine(n = 40, len = 1, f=f, fprime=fprime, f2prime=f2prime) 
qplot(x=x, xend=x, y=y+ellx4.u, yend=y-ellx4.l, geom="segment", data=dframe, linetype=I(1)) +   
   theme(panel.background=element_blank(), axis.title = element_blank()) + 
   coord_equal(ratio=1)+ 
   xlab("x") + ylab("y") +
   scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), minor_breaks=minor.axis.correction,
                      labels=c("0", expression(paste(pi,"/2")), expression(pi), expression(paste("3",pi, "/2")), expression(paste("2",pi))))
@
\caption{Quadratic correction }
\end{subfigure}
\caption[Quadratic Approximation]{
In the quadratic approximation top and bottom segments of the vertical lines are adjusted separately.
}
\label{fig:GeneralQuadraticCorrection} 
\end{figure}

Adjusting the top and bottom segments of the vertical lines separately so that the extant width is constant breaks the illusion, but slightly distorts the sinusoidal shape of the peaks.

Figure \ref{fig:GeneralQuadraticCorrection} shows the correction factor based on a quadratic approximation compared to the untransformed data. 


%As shown in Figure \ref{quadratic-GeneralCorrection}, the solution of this equation provides endpoints $(x_l, y_l)$ and $(x_2, y_2)$ which can then be used to compute the extant width of each half-segment $m$. 

Unlike the linear solution, the half-segments here are not necessarily of the same length, and thus there are separate correction factors for each half-segment. 
%The correction factors are $(\ell/2)/(m_u)$ and $(\ell/2)/(m_l)$ respectively. 
<<CtsQuadratic, echo=FALSE, include=FALSE, fig.width=6, fig.height=4>>=
f <- function(x) 2*sin(x)
fprime <- function(x) 2*cos(x)
f2prime <- function(x) -2*sin(x)

suppressMessages(library(ggplot2))
dframe <- createSine(n = 400, len = 1, f=f, fprime=fprime, f2prime=f2prime)
library(reshape2)
dfm <- melt(dframe, id.var="x", measure.vars=c("ellx4.l", "ellx4.u"))
levels(dfm$variable) <- c("Bottom Segment", "Top Segment")
cairo_pdf("figure/fig-CtsQuadratic.pdf", width=6, height=4)
ggplot(aes(x=x, y=value, group=variable, linetype=variable), data=dfm) + geom_line() + 
  scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), 
                     labels=c("0", expression(paste(pi,"/2")), 
                              expression(pi), 
                              expression(paste("3",pi, "/2")), 
                              expression(paste("2",pi)))) + 
  ylab(expression(frac('\u2113', 2))) + xlab("") + 
  theme_bw() + theme(legend.position="bottom", axis.title.y=element_text(angle=0)) +
  scale_linetype_discrete(expression('Adjusted ' * frac('\u2113', 2)*'  '))
dev.off()
# dframe$type <- "Data"
# dframe.real <- createSine(n = 4000, len = 1, f=f, fprime=fprime, f2prime=f2prime)
# secantlines <- getSecantSegment(dframe.real$x, dframe, f, fprime, f2prime)
# # secantlines2 <- getAdjLength(secantlines)
# 
# dframe2 <- secantlines
# names(dframe2) <- c("x", "y", "deriv", "xstart", "xend", "ystart", "yend", "ell", "ellp", "ellm", "type", "a")
# 
# library(plyr)
# dframe2 <- rbind.fill(dframe, dframe2)
# names(secantlines)[9:10] <- c("Bottom.Segment", "Top.Segment")
# 
# library(reshape2)
# secantlines.long <- melt(secantlines, measure.vars=c("Bottom.Segment", "Top.Segment"),  variable.name="Line", value.name="len")
# names(secantlines.long)[11:12] <- c("Line", "len")
# secantlines.long <- subset(secantlines.long, abs(x-pi)<pi)
# cairo_pdf("figure/fig-wtf.pdf", width=8, height=4)
# ggplot(aes(x=x, y=len, linetype=Line), data=secantlines.long) + geom_line()+
#   scale_x_continuous(breaks=seq(0, 2*pi, by=pi/2), 
#                      labels=c("0", expression(paste(pi,"/2")), 
#                               expression(pi), 
#                               expression(paste("3",pi, "/2")), 
#                               expression(paste("2",pi)))) + 
#   ylab(expression(frac('\u2113', 2))) +
#   theme_bw() + theme(legend.position="bottom", axis.title.y=element_text(angle=0)) + scale_linetype_discrete("Adjusted \u2113/2")
# dev.off()
@

% \begin{figure}[h!tbp]\centering
% \includegraphics[keepaspectratio=TRUE, width=.8\linewidth]{figure/fig-CtsQuadratic}
% \caption{Extant Half-segment Length \todo[inline]{Which correction is used?}. The orthogonal  line segments are not symmetrical around the center line, \todo[inline]{describe for the blind.} %so symmetric correction as employed in Figure \ref{fig:linear-GeneralCorrection} leads to simultaneous over- and under-correcting. 
% \todo[inline]{In my pdf the symbol does not show up. We need to make sure that in the final pdf it does.}}\label{fig:HalfSegLength}
% \end{figure}

%\subsection{Mathematical Properties of Transformation}
The quadratic correction breaks whenever the expression in the square root of eqn~\ref{eqn.q1} becomes negative, i.e.~whenever $v^2 \pm \ell\cdot f^{\prime\prime}(x)\cdot f^\prime(x)^2 < 0$.
This happens for  combinations of large values of $\ell$, which signify a large vertical extent, or large conditional variability $E[Y|X]$, and simultaneous large changes in the slope of the main trend, i.e.~large values of the curvature $f^{\prime\prime}(x)$. In the linear approximation of $f$ the same situation leads to a massive overcorrection of the vertical lines, making the `corrected' function look almost unrecognizable. 

Similar to the correction of the $x$-axis,  we can use a weighted approach to find a balance between counteracting the illusion and representating the  original data:
%In order to balance these goals for  the quadratic correction in $y$, half-segment lengths must be weighted separately; a single segment weighting will suffice for the linear correction in $y$. 
\begin{equation}\label{eqn.ytrans.weighted}
(\ell_{new_w})(x) = (1-w) \cdot \ell_{old} + w \cdot (\ell_{new})(x)
\end{equation}

Note that for the quadratic correction in $y$, half-segment lengths must be weighted separatel.%y; a single segment weighting will suffice for the linear correction in $y$. 

% % 
% % $1 + 2f^\prime(x)^2 + f^\prime(x)^4 \pm \ell\cdot f^{\prime\prime}(x)\cdot f^\prime(x)^2 < 0$
% % 
% % $1 + (2  \pm \ell\cdot f^{\prime\prime}(x)) \cdot f^\prime(x)^2 + f^\prime(x)^4 < 0$
% % 
% % $\frac{1  + f^\prime(x)^4}{f^\prime(x)^2} < - (2  \pm \ell\cdot f^{\prime\prime}(x)) $
% 
% \todo[inline]{Add pictures comparing the 3 transformations to the untransformed data under both normal and extreme conditions.}
% \todo[inline]{Discussion: Hammock/Trig/linear breaks first,  quadratic breaks after, full optimization breaks eventually}
% As with the trigonometry correction, the linear adjustment is prone to the same overcorrection distortion shown in Figure \ref{fig:linearFixOvercorrect}.
% 
% \begin{figure}[h!tbp]
% \centering
% <<linearFixOvercorrect, dependson='data', echo=FALSE, include=FALSE>>=
% g <- function(x) 5*sin(x)
% gprime <- function(x) 5*cos(x)
% g2prime <- function(x) -5*sin(x)
% dframe <- createSine(75, len=1, f=g, fprime=gprime, f2prime=g2prime)
% ar <- 1
% qplot(x=x, xend=xend, y = g(x) -ell/2, yend=g(x) +ell/2, geom="segment", data=dframe) +
%   theme(panel.grid.major=element_blank(), 
%        panel.grid.minor=element_blank(), panel.background=element_blank(),
%        axis.title = element_blank(), axis.ticks = element_blank(), 
%        axis.text = element_blank()) + coord_equal(ratio=ar)
% 
% qplot(x=x, xend=xend, y = g(x) -ellx/2, yend=g(x) +ellx/2, geom="segment", data=dframe) +
%   theme(panel.grid.major=element_blank(), 
%        panel.grid.minor=element_blank(), panel.background=element_blank(),
%        axis.title = element_blank(), axis.ticks = element_blank(), 
%        axis.text = element_blank()) + coord_equal(ratio=ar)
% 
% qplot(x=x, xend=xend, y = g(x) -ellx4.l, yend=g(x) +ellx4.u, geom="segment", data=dframe) +
%   theme(panel.grid.major=element_blank(), panel.background = element_rect(fill = "white", 
%                 colour = "black"),
%        panel.grid.minor=element_blank(), panel.background=element_blank(),
%        axis.title = element_blank(), axis.ticks = element_blank(), 
%        axis.text = element_blank()) + coord_equal(ratio=ar)
% @
% 
% \begin{subfigure}[b]{.3\linewidth}\centering
% \includegraphics[width=\linewidth,keepaspectratio=TRUE]{figure/fig-linearFixOvercorrect1}
% \caption{$\ell=5$, Uncorrected}
% \end{subfigure}
% \begin{subfigure}[b]{.3\linewidth}\centering
% \includegraphics[width=\linewidth,keepaspectratio=TRUE]{figure/fig-linearFixOvercorrect2}
% \caption{Corrected by eqn. \ref{trigCorrection}}
% \end{subfigure}
% \begin{subfigure}[b]{.3\linewidth}\centering
% \includegraphics[width=\linewidth,keepaspectratio=TRUE]{figure/fig-linearFixOvercorrect3}
% \caption{Corrected by eqns (\ref{eqn.q1}) and (\ref{eqn.q2})}
% \end{subfigure}
% \caption{The ratio of the length of the line to amplitude of the function needs to be included in the correction. Here, the amplitude is still 1, but the length of the line is 5. The correction factor leads to a massive over correction that makes the function almost unrecognizable. The plot on the left is uncorrected, the plot on the right is `corrected'.\label{fig:linearFixOvercorrect}}
% \end{figure}

\section{Transformations in Practice -- a User Study}

Some modifications are necessary to implement the correction factor in a realistic situation in which it might not be practical for the aspect ratio of the graph to be fixed as 1. As in \citet{marie:2013}, the correction factor necessary to remove the illusion depends on the aspect ratio of the graphs. %Figure~\ref{fig:trigFix} demonstrates the relative effectiveness of the correction factor.


\subsection{Applet Description}


\begin{figure}\centering
\includegraphics[width=.9\linewidth]{images/shiny.pdf}
\caption{\label{fig:shiny.app} Screenshot of the shiny application used to collect information of observers' preference with respect to an optimal correction for the illusion  under each of the  transformations discussed in the previous section. }
\end{figure}
%
%An applet demonstrating the effect of changing parameter values on the strength of the illusion can be found at \url{http://www.michaelbach.de/ot/sze_sineIllusion/index.html}. 
An applet demonstrating the effect of changing parameter values on the strength of the illusion as well as all of the correction factors we propose in this paper can be found at \url{http://glimmer.rstudio.com/srvanderplas/SineIllusion/}. This applet was used in collecting data from users and can be found at \url{http://glimmer.rstudio.com/srvanderplas/SineIllusionShiny/}. Figure~\ref{fig:shiny.app} shows a screen shot of it. The applet is implemented in {\tt shiny} \citep{shiny}. Users can adjust the amount of adjustment using the plus and minus button (with plus indicating a higher level of correction). Underlying this adjustment is the value of the weight $w$, as defined in eqns.~\ref{eqn.xtrans.weighted} and~\ref{eqn.ytrans.weighted}. 
\newdo{why does controlling for aspect ratio and the function imply a use of the linear approximation? I don't see the causal relationship.} As the aspect ratio and function are controlled in this app, we used the linear transformation in $y$; the transformation does not break under any combination of parameters tested in this experiment. Participants were recruited from Amazon Mechanical Turk and the \href{reddit}{http://reddit.com} community.

% 
% 
% M Bach's applet  gives the option to compensate the line length manually for its perceived shortcoming. The amount of compensation chosen turns out to be highly dependent on both the length of the vertical line segments and the amplitude of the sine function. While the applet does not provide details on the compensation function, it does suggest that it may be possible to correct the graphical display so that the brain interprets the stimuli in a manner consistent with the numerical data. 

<<study-weight-dist,include=FALSE,eval=FALSE>>=
# Weight values possible in the Shiny App.
diffs <- c(0, .5, .5, .5, .5, .25, .25, .25, .25, .25, .25, .25, .25, .1, .1, .05, .05, .05, .05, .05, .05, .025, .025, .025, .025, .025, .025, .025, .025, .025, .025, .025, .025, .05, .05, .05, .05, .1, .1, .1, .1, .1, .25, .25, .25, .25, .25, .25, .5, .5, .5, .5)
wopts <- -4 +cumsum(diffs)
qplot(x=wopts, geom="density") + geom_rug()
@

\subsection{Study Design}

The goal of the study is to determine an overall `optimal' setting for the weights in each of the correction factors. It is of additional interest to determine whether and how much this setting is subject-specific or population-based, whether the optimal setting depends on the starting value, and how much within-subject variability we find compared to between-subject variability. 

% setup of the study
\newdo{Could you put the factors of the study into a table for a better overview?}
Once a participant arrives at the site, he/she is presented with a specific setting of the weight $w$, where for the first six evaluations $w$ is randomly chosen from the set of numbers $\{0, 1, c\}, c\in(.25, .75)$. The first six stimuli consist of the sine illusion, corrected in $x$ or $y$ with weight $w$, so that each participant is exposed to a factorial combination of three weights and the two correction types. Participants are free to adjust up to thirty graphs, so after the initial six, $w$ is randomly sampled from distribution centered at 0.6 with mass on $(-4, 5)$. %wopts and graph are in study-weight-dist above
This allows us to fully explore the space of plausible $w$ while focusing on weights in the $(0,1)$ interval.

%The range of weight values the shiny app allows follows the full distribution of $w$ described above, so possible weight values are between $(-4, 5)$. 
Participants adjust the graph using increment and decrement buttons, and click ``submit'' to proceed to the next stimuli when they are satisfied with the adjustment. This provides a clear starting value and ending value, allowing us to assess the range of optimal values for each participant. Two ``training'' trials were provided that additionally superimposed a graph of the underlying mean function to give participants some idea of the underlying function the lines represent. This approach was taken to reduce the incidence of extremely high ``x'' correction values, because when $w>\!\!>1$, the lines still look to be of equal length but the underlying function bears little resemblance to $\sin(x)$. 


\newtext{A single `trial' begins with the presentation of a graph at the chosen starting weight, and ends when the participant submits the trial. Trials with less than two total interactions (i.e. at least one adjustment plus a submission at the end of the trial) were removed because of the likelihood that the participant did not complete the required task for that trial. Trials that participants skipped were also removed from the data before analysis. Participants were asked to complete at least 10 trials after the training trials; any participants who completed fewer than 4 post-training trials were removed before data analysis.}

\subsection{Method}
\subsection{Results}
<<results-analysis,echo=FALSE, cache=TRUE, include=FALSE, fig.width=8, fig.height=6>>=
trial.sum <- read.csv("./data/SummaryTable.csv", row.names=1, stringsAsFactors=FALSE)
trial.sequence <- read.csv("./data/IndivTrajectory.csv", row.names=1, stringsAsFactors=FALSE)
library(lubridate)
trial.sequence$time2 <- ymd_hms(trial.sequence$time2)


#--- Mixed Model ---#

is.outlier <- function(x){
  qs <- as.numeric(quantile(x, c(.25, .75)))
  iqr <- diff(qs)
  lims <- qs + c(-1, 1)*1.5*iqr
  !(x>=lims[1] & x <= lims[2])
}

trial.sum <- ddply(trial.sum, .(startweight), transform, 
                      incl.startwt = startweight<=1 & startweight>=0,
                      incl.trials = ntrials>3,
                      endwt.outlier = is.outlier(endweight)) 
# compute outliers for each possible start weight

noutliers <- sum(trial.sum$endwt.outlier)

lm.data <- subset(trial.sum, incl.startwt & incl.trials & !endwt.outlier, stringsAsFactors=FALSE)

# #--- Plot to compare bivar. density before/after trimming
# temp <- rbind.fill(cbind(trial.sum, dataset="full"), cbind(lm.data, dataset="trimmed"))
# # not much has changed density wise...
# ggplot(data=temp, aes(x=startweight, y=endweight)) + 
#   geom_contour(aes(group=dataset, colour=dataset), stat="density2d") + 
#   scale_colour_manual("Data", values=c("red", "blue"))+
#   xlab("Starting Weight") + ylab("Submitted \"Correct\" Weight") + 
#   facet_wrap(~type) + ggtitle("The Effect of Starting Weight on Submitted Weight")
# rm("temp")

# polygon contour plot of submitted vs starting weight for x and y
# ggplot(data=lm.data, aes(x=startweight, y=endweight)) + geom_polygon(aes(fill=..level.., group=..piece..), stat="density2d", alpha=.5) + xlab("Starting Weight") + ylab("Submitted \"Correct\" Weight") + facet_wrap(~type) + ggtitle("The Effect of Starting Weight on Submitted Weight") + xlim(c(-.2, 1.15))

# stats
nparticipants <- length(unique(subset(trial.sum, incl.startwt&incl.trials)$fingerprint))
ntrials <- nrow(subset(trial.sum, incl.startwt&incl.trials))

trials.per.participant <- mean(ddply(lm.data, .(fingerprint), summarise, ntrials=mean(ntrials))$ntrials)

set.seed(82187)
library(lme4)
library(multcomp)
library(memisc) # latex output for lmer 
# Much more complicated to examine...
lm.data$type <- relevel(factor(lm.data$type), ref="y")

modeltest <- lmer(endweight ~ type -1 + startweight + (type-1|fingerprint), data=lm.data)
summary(modeltest)
# conclusion - within-user variance is very similar for different trial types

model <- lmer(data=lm.data, endweight~ (type-1) + startweight + (1|fingerprint))

summary(model)
N <- 100
model.mcmc <- mcmcsamp(model, N, saveb=TRUE)

fixef.model <- as.data.frame(t(attr(model.mcmc, "fixef")))
names(fixef.model) <- c("x", "y", "weight")
fixef.model <- melt(fixef.model, id.vars=3)
names(fixef.model) <- c("weight", "type", "intercept")
ranef.model <- as.data.frame(t(attr(model.mcmc, "ranef")))
ranef.model <- cbind(trial = 1:N, ranef.model)
names(ranef.model) <- c("trial", paste("X", 1:125, sep=""))

sim.data <- cbind(fixef.model, rbind(ranef.model, ranef.model))

sim.data <- melt(sim.data, id.vars = 1:4)
sim.data$ub <- sim.data$weight + sim.data$intercept
sim.data$lb <- sim.data$intercept
names(sim.data)[5:6] <- c("user", "ranef")
sim.data <- melt(sim.data, id.vars = 1:6)
names(sim.data)[7:8] <- c("limit", "fixef")
sim.data$eu.level <- sim.data$ranef + sim.data$fixef

sim.data$limit <- relevel(sim.data$limit, ref="lb")
sim.data$limit <- mapvalues(sim.data$limit, from=c("lb", "ub"), to=c("from below", "from above"))
levels(sim.data$type) <- c("Transformation of X axis", "Transformation in Y")

ints <- ddply(sim.data, .(type, limit), function(x){
  temp <- HPDinterval(t(x$fixef))
  data.frame(lb = temp[1], med = median(x$fixef), ub = temp[2])
})
names(ints) <- c("type", "limit", "xmin", "x",  "xmax")

ints.users <- ddply(sim.data, .(user, type, limit), function(x){
  temp <- HPDinterval(t(x$eu.level))
  data.frame(lb = temp[1], med = median(x$eu.level), ub = temp[2])
})
names(ints.users) <- c("user", "type", "limit", "xmin", "x", "xmax")

ests <- data.frame(ests = c(fixef(model)[1:2], fixef(model)[1:2]+fixef(model)[3]), type=rep(c("Transformation in Y", "Transformation of X axis"), 2))

ggplot() + 
  geom_histogram(data=subset(sim.data, user=="X1"), aes(x=fixef, y=..density.., group=limit, fill=limit), alpha=0.8, binwidth=.01) + 
  geom_vline(xintercept=c(0,1)) +
  geom_line(data=subset(sim.data), 
               aes(x=eu.level, y=..density.., color = limit, group=interaction(user, limit)), alpha=.075, stat='density', trim=TRUE) + 
  facet_grid(type~., scales="free") + 
  ylab("Density") + xlab("Weight w") + 
  scale_colour_discrete("Approach") +
  scale_fill_discrete("Approach") + 
  ggtitle("Individual and Group Level Simulations for Optimal Weight Values") + 
  geom_errorbarh(aes(xmin=xmin, x=x, xmax=xmax, y=30, color=limit), data=ints) + 
  theme(legend.position="bottom") + geom_point(aes(x=ests, y=30), data=ests) #+ geom_point(aes(x=eu.level, y=0, colour=limit), alpha=0.3, data=subset(sim.data, user=="X1"))

@
\newtext{\Sexpr{nparticipants} participants in total took part in the study with \Sexpr{ntrials} total evaluations. 
For each starting weight, responses more than 1.5*IQR from the upper and lower quartiles were removed (a total of \Sexpr{noutliers} trials). Additionally, observations from participants who completed fewer than 4 non-outlier trials were removed from the data to allow estimation of individual random effects with some accuracy. The mean number of trials per participant once outliers were removed was \Sexpr{round(trials.per.participant, 2)}. As there were only \Sexpr{sum(!trial.sum$incl.startwt & trial.sum$incl.trials & !trial.sum$endwt.outlier)} trials with starting weight outside of [0,1] which met the other inclusion criteria, those trials were eliminated from the analysis. }


\begin{figure}[htbp]
\centering
\includegraphics[keepaspectratio=TRUE, width=.9\linewidth]{figure/fig-results-analysis}
\caption{\label{fig:MixedModelResults} Simulation results from the fitted model, facetted by correction type. Fixed effects results are shown as histograms; the red values display the results when starting from an uncorrected plot and are concentrated around $w=.15$; the blue values represent user-chosen weights when starting from a fully corrected plot and are concentrated around $w=.64$. Additionally, 95\% HPD intervals are shown above the histograms; these intervals are for the lower and upper bounds of the ``preferred weight interval'' tested in the experiment. User-level density curves show the individual variability around each fixed effect.}
\end{figure}

\newdo{Describe the reason for the approach taken - connect to sensory experiments that try to bound perceptual effects by approaching from both above and below.}
\newtext{Figure \ref{fig:MixedModelResults} shows density plots which demonstrate the relationship between the starting weight value and the user-submitted ``optimal'' weight value. 

In order to account for user-level variability, we fit a random effects model for the corrected weight value as a function of the starting weight and trial type, with a random effect for participant. The random effects for each trial type were similar, so it is appropriate to fit a single model in order to better estimate the random effects. Additionally, the interaction between starting weight and trial type was not significant, and was thus removed from the model.}

<<modelres, echo=FALSE, include=TRUE>>=
summary(model)
@
\newtext{MCMC simulations from the posterior distrubution for each of the coefficients suggest that the optimal $w$ lies between \Sexpr{round(ints$x[1], 3)} and \Sexpr{round(ints$x[2], 3)} for $x$ and \Sexpr{round(ints$x[3], 3)} and \Sexpr{round(ints$x[4], 3)} for $y$. This suggests that either correction is preferrable to an uncorrected graph, and that a weighted correction is preferrable to the fully corrected graph, as neither 0 nor 1 is contained in any overall interval. }


<<fixefIntervals,echo=FALSE,include=TRUE>>=
ints$fixef
@


XXX our evidence: 0 is not in the posterior interval ...


\section{Application: USHCN Data}
We will demonstrate the occurrence of the sine illusion as well as the suggested transformations at the example of data from the United States Historical Climatology Network \cite[USHCN;][]{ushcn, ushcn2}.

<<readdata, echo=FALSE>>=
ushcn <- na.omit(read.csv("data/subushcn.csv"))
#monthly <- read.csv("data/monthly-avgs.csv")
#write.table(gsub("#", "*", scan("http://cdiac.ornl.gov/ftp/ushcn_v2_monthly/ushcn-stations.txt", "character", sep="\n")), "data/stations", row.names=FALSE, quote=FALSE)
#stations <- read.fwf("data/stations", widths=c(6, 9, 10, 7, 3, 31, 7, 7, 7, -2, 1), skip=1, stringsAsFactors=FALSE, strip.white=TRUE)
#names(stations) <- c("ID", "Lat", "Long", "Elevation", "State", "Name", "C1", "C2", "C3", "UTCOffset")
#stations[,1] <- paste("0", as.character(stations[,1]), sep="")
#stations[,7:9] <- apply(stations[,7:9], 2, function(str) gsub("------", "", str))
#stations[,1] <- sapply(stations[,1], function(i) substr(i, nchar(i)-5, nchar(i)), USE.NAMES=FALSE)
#stations[,c(5, 6)] <- apply(stations[,5:6], 2, factor)
#stations[,c(1, 7:9)] <- apply(stations[,c(1, 7:9)], 1, function(i) paste("USH00", i, sep=""))

#station.sub <- subset(stations, abs(Lat-35)<5 & Elevation<500)
#write.csv(station.sub, "data/substations.csv", row.names=FALSE)
station.sub <- read.csv("data/substations.csv")
#ushcn.full <- ushcn
#monthly.full <- monthly

# ushcn <- subset(ushcn, ID%in%station.sub$ID)
library(plyr)
suppressMessages(require(lubridate))
suppressMessages(require(ggplot2))
monthly <- ddply(ushcn, .(Time, Month), summarize, sd=sd(value), avg=mean(value), month=unique(Month))
names(monthly) <- c("time", "Month", "sd", "avg", "month")

ushcn$Time <- as.Date(ushcn$Time)
monthly$time <- as.Date(monthly$time)
@

\begin{figure}[hbtp]
\centering
<<rawtemp, dependson='readdata', echo=FALSE, echo=FALSE, fig.width=12, fig.height=4.5, out.width='\\textwidth',cache=TRUE>>=
ggplot()  + geom_jitter(aes(Time, value/100), data=subset(ushcn, Year>1995), size=1) + 
  geom_line(aes(time, avg/100), data=subset(monthly, year(time)>1995), colour="steelblue", size=1.5) + 
  ylab("Temperature (in Celsius)") + theme_bw() + theme(plot.margin = unit(c(0,6,0,0), "cm")) + xlab("Year")
# ggsave(file="figure/monthly-temps.pdf", width=12, height=4.5)

suppressMessages(suppressWarnings(require(maps)))
states <- map_data("state")
p <- ggplot() + geom_polygon(aes(long, lat, group=group), fill="grey80", data=states) + theme_bw() + 
  theme(panel.grid.major=element_blank(), panel.background = element_blank(),
       panel.grid.minor=element_blank(), #panel.border = element_blank(),
       axis.title = element_blank(), axis.ticks = element_blank(), 
       axis.text = element_blank(), plot.margin = unit(c(-1,-1,-1,-1), "cm")) +
  geom_point(aes(Long, Lat), colour="black", size=1.25, data=station.sub)

vp1 <- viewport(x = 0.955, y = 0.91, height = unit(2.5, "cm"), width =  unit(4, "cm"), just = c("right","top"))
  
print(p, vp = vp1)
@
% \includegraphics[width=\textwidth]{monthly-temps}
\caption{Raw monthly maximum temperatures (in Celsius) between 1996 and 2012 at 422 stations across the US (as indicated on the map) with similar elevation and latitude. The blue line shows fitted temperatures from a baseline model. The plot suggests that the model fails to capture the more extreme values in summer and winter. \label{fig:raw-temp}}
\end{figure}

\begin{figure}[hbtp]\centering
<<boxtemp, dependson='readdata', echo=FALSE, fig.width=12, fig.height=4.5, out.width='\\textwidth',cache=TRUE>>=
ggplot()  + geom_boxplot(aes(Time, value/100, group=interaction(Year, Month)), outlier.size=1, fill = "grey65", data=subset(ushcn, Year>1995)) + theme_bw() + 
  #geom_line(aes(time, avg/100), data=subset(monthly, year(time)<1995), colour="steelblue", size=1.5, alpha=.5) + 
  ylab("Temperature (in Celsius)")+ xlab("Year")
# ggsave(file="figure/monthly-temps.pdf", width=12, height=4.5)
@

\caption{Monthly boxplot of maximum temperatures (in Celsius) between 1996 and 2012 at 422 stations. The boxplots suggest that there is more variation in the winter months than in the other seasons. Summer, Fall and Spring appear to have similar temperature variability, and there are more outliers in the Summer.}\label{fig:boxplot-temp}\label{fig:box-temp}
\end{figure}


\begin{figure}[h!tbp]\centering
<<residtempboxplot, dependson='residtemp', echo=FALSE, echo=FALSE, fig.width=12, fig.height=4.5, out.width='\\textwidth'>>=
ggplot()  + geom_boxplot(aes(Year+(Month-1)/12, resid/100, group=Year+(Month-1)/12), data=subset(ushcn, Year>1995), size=1) + 
  # geom_hline(yintercept=0, colour="steelblue", size=1) + 
  ylab("Residual temperature (in Celsius)") + theme_bw() + xlab("Time")
# ggsave(file="figure/monthly-resid-temps.pdf", width=12, height=4.5)
@
\caption{Boxplots of the de-seasonalized residuals provide more insight into the seasonal variance: Winters show more variation in temperatures, while summers show much less variation in temperatures. \label{fig:boxplot-resid-temp}}
\end{figure}
Figure \ref{fig:raw-temp}  shows temperature data from 422 stations across the US with similar elevation and latitude. Raw monthly temperatures are overlaid by a fit from a `baseline' model. The deviations from the fit in the extremes of the fit suggest that the baseline model is not quite able to capture all of the variability in summer and winter peaks. However, the model used is actually based on averages in each time point. This model is not susceptible to shrinkage, so the question of higher variability in the peaks becomes the question of separating this perceived variability into the part introduced by the illusion and the part actually present in the data.

\paragraph{Trend removal}
After removing the averages in Figure \ref{fig:boxplot-temp} to yield Figure \ref{fig:boxplot-resid-temp} the impression of higher variability in the peaks is only partially confirmed: there is higher variability in the winter, and lower variability in the summer, though there are more outliers in the summer than in the winter.


\paragraph{Transformation in $X$}
\todo[inline]{figure of transformation and discussion}
\paragraph{Transformation of $Y$}
\todo[inline]{figure of transformation and discussion}

%\clearpage
\section{Conclusion}
\begin{itemize}\item Raise Awareness\item ``Fixing" data is tricky and usually beyond a statistician's comfort zone, but we could see this as part of an applet where the ``fix" is done temporarily as a diagnostic measure

Such a correction is significant not only because of its effect on statistical graphics, but because previously attempts to resolve optical illusions using geometry have not met with success \citep{westheimer2008illusions}.

\item iterative process - we're only doing first step. but then we don't have an explicit functional expression anymore
\item we're only extending line lengths -- some normalization might help
\item there's a long tradition in other disciplines of adjusting work for human cognition, e.g.~painters correct (what exactly? color shades based on context), architecture: columns of Parthenon are curved to appear straight,  floor and top are curved inwardly to appear straight from a distance.
\item transformations allows us to keep the context, whereas best practice of trend removal does not do that and requires extra cognitive load to process the information.
\end{itemize}
%
%
\bibliographystyle{asa}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{references}
\clearpage
%
%
\begin{appendix}
\section{Transformation of the horizontal axis}\label{app.xtrans}
As the slope is determined by the aspect ratio, we are free to choose it and w.l.o.g. we get for each piece $T_i$: 
\[
f(T_i(x)) = \pm a x + b_i.
\]
This means that $T_i$ is essentially an inverse of function $f$, with each piece defined by the   intervals on which the inverse of $f$ exists: let $\left\{x_0 = \min(x), x_1, ..., x_{K-1}, x_K = \max(x) \right\}$ be the set of values with local extrema enhanced by the boundaries of the $x$-range, i.e.  $f^\prime(x_i) = 0$ for  $i = 1, ... , K-1$ and $f^\prime(x) \neq 0$ for any other values of $x$. 
Then each interval of the form $(x_{i-1}, x_i)$ defines one piece $T_i$ of the transfomation function $T(x)$. We will define $T_i$ now as a combination of a linear scaling function and the inverse of $f$, which we know exists for interval $(x_{i-1}, x_i)$.

Let function $s = \s{[a,b]}{[c,d]}$ be the linear scaling function that maps  the interval $(a,b)$ linearly to the interval $(c,d)$. This function is formally defined as
\[
s(x) = \s{[a,b]}{[c,d]} (x) = (x-a)/(b-a) \cdot (d-c) + c \text{ for all } x \in (a,b).
\]
Note that the slope of function $s$ is given as
\[
s^\prime(x) = (d-c)/(b-a).
\]
%
Two scaling functions can be evaluated one after the other, only if the image (i.e. $y$-range) of the first coincides with the domain (i.e. $x$-range) of the second. This consecutive execution results in another linear scaling: 
\[
\s{[e,f]}{[c,d]}  \left(  \s{[a,b]}{[e,f]}(x) \right) = \s{[a,b]}{[c,d]} (x)
\]


In our situation let the scaling function $s$ be given as:
\[
\s{[c,d]}{f([x_{i-1}, x_i])}(x) = f(x_{i-1}) + (x-c)/(d-c) \cdot (f(x_{i}) - f(x_{i-1}))),
\]
where $f([x_{i-1}, x_i])$ is defined as the interval given by $(\min(f(x_{i-1}), f(x_i)), \max(f(x_{i-1}), f(x_i)))$.
Note that $s$ has either a positive or negative slope depending on whether $f(x_{i-1})$ is smaller or larger than $f(x_i)$, respectively.

Then the transformation in the $x$-axis, $T(x)$ is defined piecewise as a combination of $T_i$, where each $T_i$ is given as:
\begin{eqnarray}\label{eq.x.transformation}
T_i(x) &=& f^{-1}\left( \s{[c_i,d_i]}{f([x_{i-1}, x_i])}(x) \right). 
\end{eqnarray}
%
Using this definition for the transformation makes $f(T(x))$ a piece-wise linear function with parameters $c_i$ and $d_i$, i.e. for $x \in (c_i,d_i)$ we have
\[
f(T(x)) = f (f^{-1}(\s{[c_i,d_i]}{f([x_{i-1}, x_i])}(x))) = \s{[c_i,d_i]}{f([x_{i-1}, x_i])}(x).
\]
Correspondingly, the slope of $f(T_i(x))$ is $(f(x_{i}) - f(x_{i-1})))/(d_i-c_i)$.
In order to make the slope the same on all pieces $T_i$ of $T$, we need to define $c_i$ and $d_i$ with respect to the function values on the interval $(x_{i-1}, x_i)$. There are various options, depending on how closely the $x$-range of $T$ should reflect the original range:
for $[c_i, d_i] = \range {f([x_{i-1}, x_i])}$ the new $x$-range is the range of $f$ on $(x_{i-1}, x_i)$, but with the advantage that the scaling function simplifies to the identity or a simple shift.

In order to preserve the original $x$-range, we need to invest into a bit more work for the scaling. With an identity scaling, each $T_i$ maps from the range of $f$ on $(x_{i-1}, x_i)$ to the same range. Overall we can therefore set up the function $T$ to map from the interval given by the sum of the function's `ups' and `downs', i.e.
$(0, \sum_{i=0}^K |f(x_i) - f(x_{i-1})|)$, to the range of $f$ on $(x_0, x_K)$.  This ensures that all pieces $f(T_i)$ have the same slope (of $|1|$).We can then use another - global - linear scaling function to map from the range of $x$, i.e. interval $(x_0, x_K)$ to $(0, \sum_{i=0}^K |f(x_i) - f(x_{i-1})|)$, yielding a transformation function $T$ of

\[
T (x) =  (f^{-1} \circ \s{[c_i,d_i]}{f([x_{i-1}, x_i])} \circ \s{(x_0, x_K)}{(0, \sum_{i=0}^K |f(x_i) - f(x_{i-1})|)}) (x),  
\]
where $c_i$ and $d_i$ are given as 
\[
c_i = \sum_{j=0}^{i-1} |f(x_j) - f(x_{j-1})| \text{ and } d_i = \sum_{j=0}^{i} |f(x_j) - f(x_{j-1})|.
\]
We can write the difference $|f(x_j) - f(x_{j-1})|$ as $\int_{x_{j-1}}^{x_j} |f^\prime(z)|dz$. This shows equation (\ref{eqn.xtrans}).
\section{Reformulation of the quadratic approximation}\label{app.quadratic}
A quadratic equation in $\lambda$ of the form 
\begin{equation}\label{quadratic.equation}
a\lambda^2 + b\lambda + c = 0,
\end{equation}
where $a, b,$ and $c$ are real-valued parameters the solutions take on the form
\[
\lambda_{\pm} = \frac{-b \pm \sqrt{b^2 - 4ac}}{2a}  \stackrel{*}{=} 2c\left(-b \pm \sqrt{b^2 - 4ac}\right)^{-1}.
\]
$^*$ if $b \neq \pm \sqrt{b^2 - 4ac}$, i.~e. $a, c \neq 0$.
\paragraph{Application to quadratic approximation to $f$:}
in the example, we have the following equivalencies:
\begin{eqnarray*}
a &=& f^{\prime\prime}(x_0) f^\prime(x_0)^2 \\
b &=& 2(1 + f^\prime(x_0)^2) \hspace{.5in} > 0 \text{ for all } x \\
c &=& \pm \ell 
\end{eqnarray*}
For a valid solution for the correction factor, we have to assume that $\lambda$ is a factor that extends the original extant width (in absolute value). \todo[inline]{Im not quite sure why the other values are not solutions, but they lead to solutions that don't work.}
%This means that for $c = - \ell$, we can only make use of $\lambda_{-}$, while for $c = +\ell$, the only valid solution is given as $\lambda_{+}$:
\begin{eqnarray*}
\lambda_{1/2} &=& \ell \left(v + \sqrt{ v^2 \pm  f^{\prime\prime}(x_0) f^\prime(x_0)^2\cdot \ell}\right)^{-1} 
\end{eqnarray*}
for $v = 1 + f^\prime(x_0)$. 
This gives the results as shown in equations (\ref{eqn.q1}) and (\ref{eqn.q2})
\end{appendix}
\end{document}
